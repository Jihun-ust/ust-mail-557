{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda26b45",
   "metadata": {},
   "source": [
    "# Generalized Linear Models (GLMs) for Regression\n",
    "\n",
    "Fit **Poisson** regression for daily conversions (counts) and **Gamma** regression for fulfillment cost (positive continuous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a20416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, warnings\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import PoissonRegressor, GammaRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "!wget -q https://raw.githubusercontent.com/Jihun-ust/ust-mail-557/main/Regression_Forecasting/reg_for_utils.py\n",
    "import reg_for_utils as utils\n",
    "csv_path = \"https://raw.githubusercontent.com/Jihun-ust/ust-mail-557/main/Regression_Forecasting/marketing_daily.csv\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv(csv_path, parse_dates=[\"date\"]).sort_values(\"date\")\n",
    "train, test = utils.time_train_test_split(df, \"date\", test_days=90)\n",
    "\n",
    "X_cols = [\"search_spend\",\"social_spend\",\"display_spend\",\"promo\",\"price_index\",\"temp_F\",\"rain\",\"is_weekend\"]\n",
    "X_train, X_test = train[X_cols], test[X_cols]\n",
    "\n",
    "# Poisson (counts)\n",
    "y_train_p = train[\"conversions\"].astype(float)\n",
    "y_test_p = test[\"conversions\"].astype(float)\n",
    "\n",
    "pre_p = ColumnTransformer([(\"num\", StandardScaler(), [\"search_spend\",\"social_spend\",\"display_spend\",\"price_index\",\"temp_F\"]),\n",
    "                           (\"cat\", OneHotEncoder(drop=\"if_binary\"), [\"promo\",\"rain\",\"is_weekend\"])])\n",
    "\n",
    "pois = Pipeline([(\"pre\", pre_p), (\"est\", PoissonRegressor(alpha=0.1, max_iter=2000))])\n",
    "pois.fit(X_train, y_train_p)\n",
    "pred_p = np.maximum(0, pois.predict(X_test))\n",
    "print(\"Poisson — MAE:\", utils.mae(y_test_p, pred_p), \"RMSE:\", utils.rmse(y_test_p, pred_p))\n",
    "\n",
    "# Gamma (positive continuous)\n",
    "y_train_g = train[\"fulfillment_cost\"].clip(lower=1e-3)\n",
    "y_test_g = test[\"fulfillment_cost\"].clip(lower=1e-3)\n",
    "\n",
    "pre_g = pre_p\n",
    "gamma = Pipeline([(\"pre\", pre_g), (\"est\", GammaRegressor(alpha=0.1, max_iter=4000))])\n",
    "gamma.fit(X_train, y_train_g)\n",
    "pred_g = np.maximum(1e-3, gamma.predict(X_test))\n",
    "print(\"Gamma — MAE:\", utils.mae(y_test_g, pred_g), \"RMSE:\", utils.rmse(y_test_g, pred_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b981ec3",
   "metadata": {},
   "source": [
    "> Note: GLMs model the **mean** via a link function and assume a distribution (Poisson/Gamma). We report MAE/RMSE for simplicity in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76418fb",
   "metadata": {},
   "source": [
    "### (Optional) Diagnostics\n",
    "Diagnostics helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common helpers for GLM diagnostics\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, warnings\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def rmse(y, yhat): return float(np.sqrt(mean_squared_error(y, yhat)))\n",
    "\n",
    "def _final_est(pipe):  # last step \"est\"\n",
    "    return pipe.named_steps[\"est\"] if isinstance(pipe, Pipeline) else pipe\n",
    "\n",
    "def _preproc(pipe):    # first step \"pre\"\n",
    "    return pipe.named_steps[\"pre\"] if isinstance(pipe, Pipeline) else None\n",
    "\n",
    "def fitted_mu(pipe, X):\n",
    "    \"\"\"Model mean on natural scale (mu).\"\"\"\n",
    "    return np.asarray(pipe.predict(X), dtype=float)\n",
    "\n",
    "def fitted_eta(pipe, X):\n",
    "    \"\"\"Linear predictor (link scale): eta = Xβ + intercept, using the pipeline's transformed X.\"\"\"\n",
    "    est = _final_est(pipe)\n",
    "    P = _preproc(pipe)\n",
    "    Xt = P.transform(X) if P is not None else X.values\n",
    "    return np.asarray(Xt @ est.coef_ + est.intercept_, dtype=float)\n",
    "\n",
    "def pearson_residuals(y, mu, family):\n",
    "    \"\"\"Pearson residuals: (y - mu)/sqrt(V(mu))\"\"\"\n",
    "    if family == \"poisson\":\n",
    "        V = mu\n",
    "    elif family == \"gamma\":\n",
    "        V = mu**2\n",
    "    else:\n",
    "        raise ValueError(\"family must be 'poisson' or 'gamma'\")\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        r = (y - mu) / np.sqrt(np.maximum(V, 1e-12))\n",
    "    return r\n",
    "\n",
    "# Convenience: pull aligned validation/test frames\n",
    "X_te = X_test.copy()\n",
    "y_te_p = y_test_p.copy()\n",
    "y_te_g = y_test_g.copy()\n",
    "\n",
    "mu_p = fitted_mu(pois, X_te)   # Poisson mean\n",
    "eta_p = fitted_eta(pois, X_te) # Poisson link (log)\n",
    "mu_g = fitted_mu(gamma, X_te)  # Gamma mean\n",
    "eta_g = fitted_eta(gamma, X_te)# Gamma link (log)\n",
    "\n",
    "print(f\"[Poisson]  MAE={mean_absolute_error(y_te_p, mu_p):.3f} | RMSE={rmse(y_te_p, mu_p):.3f}\")\n",
    "print(f\"[Gamma]    MAE={mean_absolute_error(y_te_g, mu_g):.3f} | RMSE={rmse(y_te_g, mu_g):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bebd98",
   "metadata": {},
   "source": [
    "### Residual plots (natural scale & link scale)\n",
    "- Natural-scale residuals should be centered around 0 without patterns.\n",
    "- On the link scale, Pearson residuals should look like white noise across η; strong patterns suggest mis-specification or missing interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals vs Fitted (natural & link scales)\n",
    "def plot_residuals_glm(y, mu, eta, family, title_prefix):\n",
    "    # Natural scale (response residuals)\n",
    "    resid_resp = y - mu\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "    ax.scatter(mu, resid_resp, alpha=0.5)\n",
    "    ax.axhline(0, color=\"k\", lw=1)\n",
    "    ax.set_xlabel(\"Fitted μ (natural scale)\")\n",
    "    ax.set_ylabel(\"Response residual (y − μ)\")\n",
    "    ax.set_title(f\"{title_prefix} — Residuals vs μ (natural)\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # Link scale (Pearson residuals vs eta)\n",
    "    r_pear = pearson_residuals(y, mu, family)\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "    ax.scatter(eta, r_pear, alpha=0.5)\n",
    "    ax.axhline(0, color=\"k\", lw=1)\n",
    "    ax.set_xlabel(\"Linear predictor η (link scale)\")\n",
    "    ax.set_ylabel(\"Pearson residual\")\n",
    "    ax.set_title(f\"{title_prefix} — Pearson residuals vs η (link)\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# Poisson\n",
    "plot_residuals_glm(y_te_p.values, mu_p, eta_p, family=\"poisson\", title_prefix=\"Poisson\")\n",
    "# Gamma\n",
    "plot_residuals_glm(y_te_g.values, mu_g, eta_g, family=\"gamma\",   title_prefix=\"Gamma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c289996",
   "metadata": {},
   "source": [
    "### Overdispersion check (Poisson only)\n",
    "- φ̂ ≈ 1 → Poisson variance ≈ mean (assumption OK).\n",
    "- φ̂ > 1 → overdispersion; consider adding features, using Negative Binomial, or robust SEs.\n",
    "- In the plot, points far above the dashed line indicate overdispersion in those ranges of μ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6634383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overdispersion diagnostics for Poisson\n",
    "y = y_te_p.values\n",
    "mu = mu_p\n",
    "n = len(y)\n",
    "\n",
    "# Approx. degrees of freedom = n − p  (use number of effective parameters from the final estimator)\n",
    "p_params = _final_est(pois).coef_.size + 1  # +1 for intercept\n",
    "df_val = max(n - p_params, 1)\n",
    "\n",
    "# Pearson chi-square / df_val (φ_hat): >1 indicates overdispersion, <1 underdispersion\n",
    "phi_hat = np.sum(((y - mu)**2) / np.maximum(mu, 1e-12)) / df_val\n",
    "print(f\"Poisson overdispersion factor (Pearson χ² / df_val): {phi_hat:.3f}  (≈1 is ideal; >1 overdispersion)\")\n",
    "\n",
    "# Mean–variance relationship: aggregate by fitted-mean bins\n",
    "bins = pd.qcut(mu, q=min(10, max(3, n//50)), duplicates=\"drop\")\n",
    "df_val_mv = pd.DataFrame({\"y\": y, \"mu\": mu, \"bin\": bins}).groupby(\"bin\").agg(mean_mu=(\"mu\",\"mean\"),\n",
    "                                                                          var_y=(\"y\",\"var\"),\n",
    "                                                                          mean_y=(\"y\",\"mean\")).reset_index(drop=True)\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "ax.scatter(df_val_mv[\"mean_mu\"], df_val_mv[\"var_y\"], alpha=0.8)\n",
    "ax.plot([df_val_mv[\"mean_mu\"].min(), df_val_mv[\"mean_mu\"].max()],\n",
    "        [df_val_mv[\"mean_mu\"].min(), df_val_mv[\"mean_mu\"].max()], linestyle=\"--\", label=\"Var = Mean (Poisson)\")\n",
    "ax.set_xlabel(\"Mean count (by bin)\")\n",
    "ax.set_ylabel(\"Observed variance (by bin)\")\n",
    "ax.set_title(\"Poisson mean–variance check\")\n",
    "ax.legend()\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0f3202",
   "metadata": {},
   "source": [
    "### Zero diagnostics\n",
    "- If observed zeros » expected zeros, your count process may be zero-inflated (consider Zero-Inflated Poisson/NB or adding a separate “structural zero” model).\n",
    "- Gamma targets should be strictly positive; zeros imply a different model (e.g., Tweedie or two-part model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poisson: expected zero rate = exp(-μ). Compare to actual zeros.\n",
    "obs_zero_rate_p = float(np.mean(y_te_p.values == 0))\n",
    "exp_zero_rate_p = float(np.mean(np.exp(-mu_p)))\n",
    "print(f\"[Poisson] Observed zero rate = {obs_zero_rate_p:.3f} | Expected (model) zero rate = {exp_zero_rate_p:.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.bar([\"Observed zeros\",\"Expected zeros (Poisson)\"], [obs_zero_rate_p, exp_zero_rate_p])\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title(\"Zero-rate comparison — Poisson\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Gamma: should not produce zeros (strictly positive). Warn if present.\n",
    "zeros_in_gamma_target = int(np.sum(y_te_g.values <= 0))\n",
    "print(f\"[Gamma] Non-positive values in target (should be none): {zeros_in_gamma_target}\")\n",
    "if zeros_in_gamma_target > 0:\n",
    "    warnings.warn(\"Gamma regression expects strictly positive targets. Consider a shifted target or a different family.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6558de21",
   "metadata": {},
   "source": [
    "### Offset sanity (Poisson only; optional)\n",
    "- With a log link, adding log(exposure) as an offset should multiplicatively scale μ by exposure. The quick check above validates your offset wiring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52582de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have an exposure column (e.g., 'impressions', 'sessions'), set it here.\n",
    "OFFSET_COL = None  # e.g., \"sessions\"  (log-offset used)\n",
    "\n",
    "if OFFSET_COL is None or OFFSET_COL not in X_te.columns:\n",
    "    print(\"No OFFSET_COL provided or not in X_test; skipping offset sanity.\")\n",
    "else:\n",
    "    # Using Poisson with log link: log(μ) = Xβ + log(exposure)\n",
    "    # sklearn doesn't accept offset directly, so we compute η and add offset at prediction time.\n",
    "    est = _final_est(pois)\n",
    "    P = _preproc(pois)\n",
    "    Xt = P.transform(X_te) if P is not None else X_te.values\n",
    "    eta_no_offset = Xt @ est.coef_ + est.intercept_\n",
    "    log_exposure = np.log(np.clip(X_te[OFFSET_COL].values.astype(float), 1e-12, None))\n",
    "    eta_with_offset = eta_no_offset + log_exposure\n",
    "\n",
    "    mu_with_offset = np.exp(eta_with_offset)\n",
    "    # Sanity: adding +log(2) to offset should ~double μ\n",
    "    mu_with_offset_x2 = np.exp(eta_with_offset + np.log(2.0))\n",
    "\n",
    "    ratio = np.median(mu_with_offset_x2 / np.maximum(mu_with_offset, 1e-12))\n",
    "    print(f\"Offset sanity: median(μ_with_offset * 2 / μ_with_offset) ≈ {ratio:.2f} (expect ~2.00)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74054512",
   "metadata": {},
   "source": [
    "### Segment errors (promo / rain / is_weekend)\n",
    "- Consistent positive/negative residuals in segments (promo/rain/weekend) indicate systematic bias → add interactions, segment-specific terms, or re-specify model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616e5e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment errors for Poisson & Gamma (by flags)\n",
    "seg_cols = [\"promo\",\"rain\",\"is_weekend\"]\n",
    "\n",
    "# Build evaluation frames aligned with X_te\n",
    "eval_df = pd.DataFrame({\n",
    "    \"date\": df.loc[X_te.index, \"date\"].values,\n",
    "    \"promo\": X_te[\"promo\"].values,\n",
    "    \"rain\": X_te[\"rain\"].values,\n",
    "    \"is_weekend\": X_te[\"is_weekend\"].values,\n",
    "    \"y_count\": y_te_p.values,\n",
    "    \"mu_count\": mu_p,\n",
    "    \"y_cost\": y_te_g.values,\n",
    "    \"mu_cost\": mu_g\n",
    "})\n",
    "\n",
    "eval_df[\"resid_count\"] = eval_df[\"y_count\"] - eval_df[\"mu_count\"]\n",
    "eval_df[\"resid_cost\"]  = eval_df[\"y_cost\"]  - eval_df[\"mu_cost\"]\n",
    "\n",
    "for seg in seg_cols:\n",
    "    if seg not in eval_df.columns: \n",
    "        continue\n",
    "    # Poisson residuals by segment\n",
    "    grp = [eval_df.loc[eval_df[seg]==v, \"resid_count\"] for v in sorted(eval_df[seg].unique())]\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    ax.boxplot(grp, labels=[str(v) for v in sorted(eval_df[seg].unique())])\n",
    "    ax.axhline(0, color=\"k\", lw=1)\n",
    "    ax.set_xlabel(seg); ax.set_ylabel(\"Count residual (y − μ)\")\n",
    "    ax.set_title(f\"Poisson residuals by {seg}\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # Gamma residuals by segment\n",
    "    grp_g = [eval_df.loc[eval_df[seg]==v, \"resid_cost\"] for v in sorted(eval_df[seg].unique())]\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    ax.boxplot(grp_g, labels=[str(v) for v in sorted(eval_df[seg].unique())])\n",
    "    ax.axhline(0, color=\"k\", lw=1)\n",
    "    ax.set_xlabel(seg); ax.set_ylabel(\"Cost residual (y − μ)\")\n",
    "    ax.set_title(f\"Gamma residuals by {seg}\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# Optional: residuals over time to spot drift\n",
    "for tgt, col in [(\"Poisson\", \"resid_count\"), (\"Gamma\", \"resid_cost\")]:\n",
    "    ts = eval_df.dropna(subset=[\"date\"]).sort_values(\"date\").copy()\n",
    "    ts[\"roll_mean_resid\"] = ts[col].rolling(window=8, min_periods=1).mean()\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    ax.plot(ts[\"date\"], ts[col], alpha=0.25, label=\"residual\")\n",
    "    ax.plot(ts[\"date\"], ts[\"roll_mean_resid\"], lw=2, label=\"rolling mean (w=8)\")\n",
    "    ax.axhline(0, color=\"k\", lw=1)\n",
    "    ax.set_title(f\"{tgt} residuals over time\")\n",
    "    ax.set_xlabel(\"date\"); ax.set_ylabel(\"residual\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
