{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0388396b",
   "metadata": {},
   "source": [
    "\n",
    "# Energy Consumption Forecasting — Method Comparison\n",
    "\n",
    "**Goal:** Compare regression approaches on an hourly energy consumption problem:\n",
    "\n",
    "1. Ordinary Linear Regression (OLS)  \n",
    "2. Regularization (Ridge / Lasso / Elastic Net)  \n",
    "3. Feature Expansion (polynomial features)  \n",
    "4. Random Forest Regression  \n",
    "5. GLM (Gamma) Regression  \n",
    "6. Quantile Regression (P10, P50, P90)\n",
    "\n",
    "Generate a realistic **synthetic hourly dataset** with seasonal, temperature, and calendar effects, then evaluate and visualize each method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102f08ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_pinball_loss\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, QuantileRegressor, GammaRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab246e1",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Create a synthetic hourly dataset (1 year)\n",
    "\n",
    "- **Seasonality**: daily (hour-of-day) and annual (day-of-year) cycles  \n",
    "- **Weather**: temperature affects usage in a U-shaped way (heating/cooling)  \n",
    "- **Calendar**: weekend/holiday effects  \n",
    "- **Noise**: larger variance at extreme temperatures (heteroscedastic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f23a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# One year of hourly data\n",
    "start = pd.Timestamp(\"2024-01-01 00:00:00\")\n",
    "end   = pd.Timestamp(\"2024-12-31 23:00:00\")\n",
    "date_range = pd.date_range(start, end, freq=\"H\")\n",
    "n = len(date_range)\n",
    "\n",
    "df = pd.DataFrame({\"timestamp\": date_range})\n",
    "df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "df[\"dow\"]  = df[\"timestamp\"].dt.dayofweek  # Mon=0\n",
    "df[\"doy\"]  = df[\"timestamp\"].dt.dayofyear\n",
    "df[\"is_weekend\"] = (df[\"dow\"] >= 5).astype(int)\n",
    "\n",
    "# Simple holiday approximation\n",
    "holidays = [\n",
    "    \"2024-01-01\",\"2024-01-15\",\"2024-02-19\",\"2024-05-27\",\n",
    "    \"2024-07-04\",\"2024-09-02\",\"2024-11-28\",\"2024-12-25\"\n",
    "]\n",
    "holidays = pd.to_datetime(holidays)\n",
    "df[\"is_holiday\"] = df[\"timestamp\"].dt.normalize().isin(holidays).astype(int)\n",
    "\n",
    "# Temperature: yearly seasonality + daily noise\n",
    "doy_rad = 2*np.pi*df[\"doy\"]/365.25\n",
    "hour_rad = 2*np.pi*df[\"hour\"]/24.0\n",
    "base_temp = 60 + 20*np.sin(doy_rad)  # colder in winter, hotter in summer\n",
    "temp = base_temp + 3*np.sin(hour_rad - np.pi/3) + np.random.normal(0, 2.5, size=n)\n",
    "df[\"temp_F\"] = temp\n",
    "\n",
    "# Hourly load base pattern (higher in morning/evening)\n",
    "load_daily = 1.0 + 0.6*np.sin(hour_rad - np.pi/2) + 0.3*np.sin(2*hour_rad)\n",
    "# Weekend and holiday effects\n",
    "weekend_effect = np.where(df[\"is_weekend\"]==1, -0.08, 0.0)\n",
    "holiday_effect = np.where(df[\"is_holiday\"]==1, -0.12, 0.0)\n",
    "\n",
    "# U-shaped temperature effect around 68F\n",
    "temp_dev = (df[\"temp_F\"] - 68.0)\n",
    "temp_u   = 0.004 * (temp_dev**2)\n",
    "\n",
    "# Compose expected mean load (kWh) and add heteroscedastic noise\n",
    "mu = 30 * load_daily * (1 + weekend_effect + holiday_effect) * (1 + temp_u)\n",
    "sigma = 1.0 + 0.12 * (np.abs(temp_dev)/10.0)\n",
    "noise = np.random.normal(0, sigma, size=n)\n",
    "\n",
    "df[\"consumption_kwh\"] = np.maximum(0.5, mu + noise)\n",
    "\n",
    "# Lags and rolling\n",
    "df[\"lag1\"]  = df[\"consumption_kwh\"].shift(1)\n",
    "df[\"lag24\"] = df[\"consumption_kwh\"].shift(24)\n",
    "df[\"roll24_mean\"] = df[\"consumption_kwh\"].rolling(24, min_periods=1).mean()\n",
    "\n",
    "# Fourier time features\n",
    "df[\"sin_hour\"] = np.sin(hour_rad)\n",
    "df[\"cos_hour\"] = np.cos(hour_rad)\n",
    "df[\"sin_doy\"]  = np.sin(doy_rad)\n",
    "df[\"cos_doy\"]  = np.cos(doy_rad)\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f0fe3",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Time-based split (train vs. test)\n",
    "\n",
    "Use the **last 6 weeks** as holdout to mimic forward-looking evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_hours = 24 * 42  # ~6 weeks\n",
    "train = df.iloc[:-holdout_hours].copy()\n",
    "test  = df.iloc[-holdout_hours:].copy()\n",
    "\n",
    "y_col = \"consumption_kwh\"\n",
    "X_cols = [\"temp_F\",\"is_weekend\",\"is_holiday\",\"lag1\",\"lag24\",\"roll24_mean\",\n",
    "          \"sin_hour\",\"cos_hour\",\"sin_doy\",\"cos_doy\"]\n",
    "\n",
    "X_train, y_train = train[X_cols], train[y_col]\n",
    "X_test,  y_test  = test[X_cols],  test[y_col]\n",
    "\n",
    "num_cols = [\"temp_F\",\"lag1\",\"lag24\",\"roll24_mean\",\"sin_hour\",\"cos_hour\",\"sin_doy\",\"cos_doy\"]\n",
    "cat_cols = [\"is_weekend\",\"is_holiday\"]\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(drop=\"if_binary\"), cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035bc58f",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Fit models\n",
    "\n",
    "Fit OLS, regularized linear models, feature-expanded linear model, Random Forest, GLM (Gamma), and Quantile Regressors (P10/P50/P90).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663173c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "# 1) OLS\n",
    "models[\"ols\"] = Pipeline([(\"pre\", pre), (\"est\", LinearRegression())])\n",
    "\n",
    "# 2) Regularization\n",
    "models[\"ridge\"] = Pipeline([(\"pre\", pre), (\"est\", Ridge(alpha=1.0, random_state=42))])\n",
    "models[\"lasso\"] = Pipeline([(\"pre\", pre), (\"est\", Lasso(alpha=0.01, random_state=42, max_iter=10000))])\n",
    "models[\"enet\"]  = Pipeline([(\"pre\", pre), (\"est\", ElasticNet(alpha=0.01, l1_ratio=0.5, random_state=42, max_iter=10000))])\n",
    "\n",
    "# 3) Feature Expansion (polynomial on numeric features only)\n",
    "poly_pre = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"sc\", StandardScaler()), (\"poly\", PolynomialFeatures(degree=2, include_bias=False))]), num_cols),\n",
    "    (\"cat\", OneHotEncoder(drop=\"if_binary\"), cat_cols)\n",
    "])\n",
    "models[\"poly2_ols\"] = Pipeline([(\"pre\", poly_pre), (\"est\", LinearRegression())])\n",
    "\n",
    "# 4) Random Forest\n",
    "models[\"rf\"] = Pipeline([(\"pre\", pre), (\"est\", RandomForestRegressor(\n",
    "    n_estimators=300, max_depth=12, min_samples_leaf=2, random_state=42, n_jobs=-1))])\n",
    "\n",
    "# 5) GLM (Gamma)\n",
    "models[\"gamma\"] = Pipeline([(\"pre\", pre), (\"est\", GammaRegressor(alpha=0.01, max_iter=5000))])\n",
    "\n",
    "# 6) Quantile (P10/P50/P90)\n",
    "for tau in [0.10, 0.50, 0.90]:\n",
    "    models[f\"qr_{int(tau*100)}\"] = Pipeline([(\"pre\", pre), (\"est\", QuantileRegressor(quantile=tau, alpha=0.0005, solver=\"highs\"))])\n",
    "\n",
    "# Fit & predict\n",
    "for name, pipe in models.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "preds = {name: pipe.predict(X_test) for name, pipe in models.items()}\n",
    "list(preds.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4955522d",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Evaluation metrics\n",
    "\n",
    "- For mean-focused models: **RMSE**, **MAE**, **R²**  \n",
    "- For quantile models: **pinball loss** at respective τ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defecbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_metrics(preds_dict):\n",
    "    rows = []\n",
    "    for name, yhat in preds_dict.items():\n",
    "        row = {\"model\": name}\n",
    "        if name.startswith(\"qr_\"):\n",
    "            tau = int(name.split(\"_\")[1])/100.0\n",
    "            row[\"pinball_loss\"] = mean_pinball_loss(y_test, yhat, alpha=tau)\n",
    "            row[\"RMSE\"] = np.nan\n",
    "            row[\"MAE\"]  = np.nan\n",
    "            row[\"R2\"]   = np.nan\n",
    "        else:\n",
    "            row[\"pinball_loss\"] = np.nan\n",
    "            row[\"RMSE\"] = float(np.sqrt(mean_squared_error(y_test, yhat)))\n",
    "            row[\"MAE\"]  = float(mean_absolute_error(y_test, yhat))\n",
    "            row[\"R2\"]   = float(r2_score(y_test, yhat))\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows).sort_values(\"model\").reset_index(drop=True)\n",
    "\n",
    "metrics_df = summarize_metrics(preds)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e43d2c",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Visual — Actual vs Predicted (OLS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27a1a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(test[\"timestamp\"], y_test, label=\"Actual\")\n",
    "plt.plot(test[\"timestamp\"], preds[\"ols\"], label=\"OLS\")\n",
    "plt.xlabel(\"Time\"); plt.ylabel(\"kWh\")\n",
    "plt.title(\"Actual vs Predicted — OLS\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb833f9b",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Visual — Actual vs Predicted (Random Forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(test[\"timestamp\"], y_test, label=\"Actual\")\n",
    "plt.plot(test[\"timestamp\"], preds[\"rf\"], label=\"Random Forest\")\n",
    "plt.xlabel(\"Time\"); plt.ylabel(\"kWh\")\n",
    "plt.title(\"Actual vs Predicted — Random Forest\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924bb876",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Visual — Actual vs Predicted (Gamma GLM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b44c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(test[\"timestamp\"], y_test, label=\"Actual\")\n",
    "plt.plot(test[\"timestamp\"], preds[\"gamma\"], label=\"Gamma GLM\")\n",
    "plt.xlabel(\"Time\"); plt.ylabel(\"kWh\")\n",
    "plt.title(\"Actual vs Predicted — Gamma GLM\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ba6d6",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Visual — Quantile band (P10–P90) with Median (P50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b0fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "q10 = preds[\"qr_10\"]\n",
    "q50 = preds[\"qr_50\"]\n",
    "q90 = preds[\"qr_90\"]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "t = test[\"timestamp\"].to_numpy()\n",
    "order = np.argsort(t)\n",
    "plt.plot(t[order], q50[order], label=\"Median (P50)\")\n",
    "plt.fill_between(t[order], q10[order], q90[order], alpha=0.2, label=\"P10–P90 band\")\n",
    "plt.plot(t[order], y_test.to_numpy()[order], label=\"Actual\")\n",
    "plt.xlabel(\"Time\"); plt.ylabel(\"kWh\")\n",
    "plt.title(\"Quantile Regression — Median with P10–P90 band\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a693517",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Visual — Residuals vs Temperature (Random Forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_rf = y_test - preds[\"rf\"]\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(test[\"temp_F\"], resid_rf, alpha=0.35, s=18)\n",
    "plt.axhline(0, linewidth=1)\n",
    "plt.xlabel(\"Temp (°F)\"); plt.ylabel(\"Residual (Actual − Pred)\")\n",
    "plt.title(\"Residuals vs Temperature — RF\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba80120",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Calibration — Empirical coverage for quantiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_coverage(y, qhat):\n",
    "    return float(np.mean(np.asarray(y) <= np.asarray(qhat)))\n",
    "\n",
    "cov50 = empirical_coverage(y_test, q50)\n",
    "cov90 = empirical_coverage(y_test, q90)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar([\"τ=0.50\",\"τ=0.90\"], [cov50, cov90])\n",
    "plt.axhline(0.5, linestyle=\"--\", linewidth=1)\n",
    "plt.axhline(0.9, linestyle=\"--\", linewidth=1)\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"P(y ≤ q̂τ)\")\n",
    "plt.title(\"Empirical Coverage — Quantile Regression\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552663f2",
   "metadata": {},
   "source": [
    "\n",
    "## 11) Rolling RMSE — stability over time (OLS vs RF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57320f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 24*7  # one week window\n",
    "def rolling_rmse(y_true, y_pred, window):\n",
    "    y = np.asarray(y_true); yhat = np.asarray(y_pred)\n",
    "    out = np.full_like(y, fill_value=np.nan, dtype=float)\n",
    "    for i in range(window-1, len(y)):\n",
    "        out[i] = np.sqrt(np.mean((y[i-window+1:i+1] - yhat[i-window+1:i+1])**2))\n",
    "    return out\n",
    "\n",
    "roll_rmse_ols = rolling_rmse(y_test, preds[\"ols\"], window)\n",
    "roll_rmse_rf  = rolling_rmse(y_test, preds[\"rf\"],  window)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(test[\"timestamp\"], roll_rmse_ols, label=\"OLS (rolling RMSE)\")\n",
    "plt.plot(test[\"timestamp\"], roll_rmse_rf,  label=\"RF (rolling RMSE)\")\n",
    "plt.xlabel(\"Time\"); plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Rolling RMSE (1-week window)\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6f4d43",
   "metadata": {},
   "source": [
    "\n",
    "### Takeaways\n",
    "\n",
    "- **OLS** provides a strong baseline but struggles with nonlinearities and varying variance.  \n",
    "- **Regularization** stabilizes linear models when features are correlated or numerous.  \n",
    "- **Feature Expansion** (polynomial, Fourier) can capture curvature without black-boxes.  \n",
    "- **Random Forest** models nonlinear interactions well, often reducing error in complex regimes.  \n",
    "- **GLM (Gamma)** respects positive, heteroscedastic consumption and can improve calibration.  \n",
    "- **Quantile Regression** gives **risk-aware** bands (P10/P90) for capacity planning and SLAs.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
