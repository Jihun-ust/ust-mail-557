{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - Subscribe Prediction\n",
    "\n",
    "1. Train two models:\n",
    "   - **Baseline Logistic Regression** (simple, interpretable)\n",
    "   - **Neural Network (MLP)** (more complex, flexible)\n",
    "2. Compare performance using clear metrics and visualizations.\n",
    "3. Highlight **what leaders should focus on** in evaluation and decision‑making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import default_rng\n",
    "import matplotlib.pyplot as plt, warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss, roc_curve, precision_recall_curve\n",
    "from sklearn.calibration import calibration_curve\n",
    "from scipy.io import arff\n",
    "\n",
    "rng = default_rng(0)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "- Author: Paulo Cortez, Sérgio Moro \n",
    "- Source: UCI \n",
    "- Cite: S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimarães, Portugal, October, 2011. EUROSIS.\n",
    "\n",
    "### Background\n",
    "The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be (or not) subscribed.\n",
    "\n",
    "The classification goal is to predict if the client will subscribe a term deposit (variable y).\n",
    "\n",
    "### Features:\n",
    "**bank client data:**\n",
    "- age (numeric)\n",
    "- job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\", \"student\",\"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\")\n",
    "- marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\n",
    "- education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n",
    "- default: has credit in default? (binary: \"yes\",\"no\")\n",
    "- balance: average yearly balance, in euros (numeric)\n",
    "- housing: has housing loan? (binary: \"yes\",\"no\")\n",
    "- loan: has personal loan? (binary: \"yes\",\"no\")\n",
    "\n",
    "**related with the last contact of the current campaign:**\n",
    "- contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\")\n",
    "- day: last contact day of the month (numeric)\n",
    "- month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
    "- duration: last contact duration, in seconds (numeric)\n",
    "\n",
    "**other attributes:**\n",
    "- campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "- pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n",
    "- previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "- poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n",
    "\n",
    "**output variable (desired target):**\n",
    "- y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "!wget -q https://raw.githubusercontent.com/Jihun-ust/ust-mail-557/main/NeuralNetwork/phpkIxskf.arff\n",
    "file_name = \"phpkIxskf.arff\"\n",
    "data, meta = arff.loadarff(file_name)\n",
    "df = pd.DataFrame(data)\n",
    "# Rename columns\n",
    "col_map = {\n",
    "    \"V1\": \"age\",\n",
    "    \"V2\": \"job\",\n",
    "    \"V3\": \"marital\",\n",
    "    \"V4\": \"education\",\n",
    "    \"V5\": \"default\",\n",
    "    \"V6\": \"balance\",\n",
    "    \"V7\": \"housing\",\n",
    "    \"V8\": \"loan\",\n",
    "    \"V9\": \"contact\",\n",
    "    \"V10\": \"day\",\n",
    "    \"V11\": \"month\",\n",
    "    \"V12\": \"duration\",\n",
    "    \"V13\": \"campaign\",\n",
    "    \"V14\": \"pdays\",\n",
    "    \"V15\": \"previous\",\n",
    "    \"V16\": \"poutcome\",\n",
    "    \"Class\": \"subscribed\"\n",
    "}\n",
    "\n",
    "df = df.rename(columns=col_map)\n",
    "\n",
    "# Convert data types\n",
    "def decode_bytes(val):\n",
    "    if isinstance(val, (bytes, bytearray)):\n",
    "        try:\n",
    "            return val.decode('utf-8')  # decode to string\n",
    "        except:\n",
    "            return str(val)  # fallback to str\n",
    "    if isinstance(val, str) and val.startswith(\"b'\"):  # string that looks like b'...'\n",
    "        return val.strip(\"b'\").strip(\"'\")\n",
    "    return val\n",
    "\n",
    "df = df.applymap(decode_bytes)\n",
    "\n",
    "# Ensure numeric columns are numeric\n",
    "num_cols = [\"age\",\"balance\",\"day\",\"duration\",\"campaign\",\"pdays\",\"previous\"]\n",
    "df[num_cols] = df[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Convert target (binary)\n",
    "df[\"subscribed\"] = df[\"subscribed\"].replace({\"1\": 1, \"2\": 0})\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split\n",
    "Hold out 20% of data for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['subscribed'])\n",
    "y = df['subscribed']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "num_cols = ['age','balance','day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "cat_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - Logistic Regression\n",
    "Simple, interpretable, runs fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('clf', LogisticRegression(max_iter=3000))\n",
    "])\n",
    "logreg.fit(X_train, y_train)\n",
    "probs_lr = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "auc_lr = roc_auc_score(y_test, probs_lr)\n",
    "pr_lr = average_precision_score(y_test, probs_lr)\n",
    "brier_lr = brier_score_loss(y_test, probs_lr)\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    \"LR result\":{\n",
    "        \"roc_auc_score\": auc_lr,\n",
    "        \"average_precision_score\": pr_lr,\n",
    "        \"brier_score_loss\": brier_lr\n",
    "    }\n",
    "})\n",
    "\n",
    "display(result.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (MLP)\n",
    "A simple feedforward network (multi‑layer perceptron). More flexible but less interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('clf', MLPClassifier(hidden_layer_sizes=(16, 8)))\n",
    "])\n",
    "mlp.fit(X_train, y_train)\n",
    "probs_nn = mlp.predict_proba(X_test)[:,1]\n",
    "\n",
    "auc_nn = roc_auc_score(y_test, probs_nn)\n",
    "pr_nn = average_precision_score(y_test, probs_nn)\n",
    "brier_nn = brier_score_loss(y_test, probs_nn)\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    \"NN result\":{\n",
    "        \"roc_auc_score\": auc_nn,\n",
    "        \"average_precision_score\": pr_nn,\n",
    "        \"brier_score_loss\": brier_nn\n",
    "    }\n",
    "})\n",
    "\n",
    "display(result.round(3))\n",
    "\n",
    "# Training Loss curve\n",
    "clf = mlp.named_steps[\"clf\"]\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(clf.loss_curve_)\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\")\n",
    "plt.title(\"MLP training loss curve\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline vs. Neural Net\n",
    "- **ROC‑AUC** (ranking quality): How well the model ranks likely buyers above non-buyers. (higher=better)\n",
    "- **PR‑AUC** (precision‑recall for rare positives): How well the model finds true buyers among the top predictions when buyers are rare. (higher=better)\n",
    "- **Brier score** (calibration): How well the predicted probabilities match reality (calibration). (lower=better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, probs_lr)\n",
    "fpr_nn, tpr_nn, _ = roc_curve(y_test, probs_nn)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f\"Logistic (AUC={auc_lr:.3f})\")\n",
    "plt.plot(fpr_nn, tpr_nn, label=f\"Neural Net (AUC={auc_nn:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--', color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall curves\n",
    "prec_lr, rec_lr, _ = precision_recall_curve(y_test, probs_lr)\n",
    "prec_nn, rec_nn, _ = precision_recall_curve(y_test, probs_nn)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(rec_lr, prec_lr, label=f\"Logistic (PR-AUC={pr_lr:.3f})\")\n",
    "plt.plot(rec_nn, prec_nn, label=f\"Neural Net (PR-AUC={pr_nn:.3f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve Comparison\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calibration (reliability) curve\n",
    "prob_true_lr, prob_pred_lr = calibration_curve(y_test, probs_lr, n_bins=12, strategy='quantile')\n",
    "prob_true_nn, prob_pred_nn = calibration_curve(y_test, probs_nn, n_bins=12, strategy='quantile')\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(prob_pred_lr, prob_true_lr, marker='o', label=f\"Logistic (Brier={brier_lr:.3f})\")\n",
    "plt.plot(prob_pred_nn, prob_true_nn, marker='o', label=f\"Neural Net (Brier={brier_nn:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"Predicted probability (bin mean)\")\n",
    "plt.ylabel(\"Observed frequency\")\n",
    "plt.title(\"Calibration\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Logistic Regression\": {\n",
    "        \"ROC-AUC (higher=better)\": auc_lr,\n",
    "        \"PR-AUC (higher=better)\": pr_lr,\n",
    "        \"Brier (lower=better)\": brier_lr\n",
    "    },\n",
    "    \"Neural Net\": {\n",
    "        \"ROC-AUC (higher=better)\": auc_nn,\n",
    "        \"PR-AUC (higher=better)\": pr_nn,\n",
    "        \"Brier (lower=better)\": brier_nn\n",
    "    }\n",
    "})\n",
    "\n",
    "display(results.T.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Making\n",
    "- **If baseline is close**: stick with logistic regression (simpler, transparent, easier to monitor).\n",
    "- **If neural net shows clear lift**: consider adopting, but demand **extra checks**:\n",
    "  - Calibration: are probabilities reliable?\n",
    "  - Fairness: does performance differ by device/country?\n",
    "  - Ops: can it run fast enough for homepage personalization?\n",
    "- **Always tie back to business metrics**: incremental conversions, ROI, and fairness guardrails.\n",
    "\n",
    "\n",
    "- The lesson: More complex is not always better. Leaders should weigh **performance vs. simplicity, interpretability, fairness, and operations**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
