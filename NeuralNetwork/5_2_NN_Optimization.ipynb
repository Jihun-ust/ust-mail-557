{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - Optimization & Regularization\n",
    "\n",
    "1. Train two models:\n",
    "   - **Neural Network (MLP): Default**\n",
    "   - **Neural Network (MLP): Optimization**\n",
    "2. Compare performance using clear metrics and visualizations.\n",
    "3. Highlight **what leaders should focus on** in evaluation and decision‑making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from numpy.random import default_rng\n",
    "import matplotlib.pyplot as plt, warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss, roc_curve, precision_recall_curve\n",
    "from sklearn.calibration import calibration_curve\n",
    "from scipy.io import arff\n",
    "\n",
    "rng = default_rng(0)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "- Author: Paulo Cortez, Sérgio Moro \n",
    "- Source: UCI \n",
    "- Cite: S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimarães, Portugal, October, 2011. EUROSIS.\n",
    "\n",
    "### Background\n",
    "The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be (or not) subscribed.\n",
    "\n",
    "The classification goal is to predict if the client will subscribe a term deposit (variable y).\n",
    "\n",
    "### Features:\n",
    "**bank client data:**\n",
    "- age (numeric)\n",
    "- job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\", \"student\",\"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\")\n",
    "- marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\n",
    "- education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n",
    "- default: has credit in default? (binary: \"yes\",\"no\")\n",
    "- balance: average yearly balance, in euros (numeric)\n",
    "- housing: has housing loan? (binary: \"yes\",\"no\")\n",
    "- loan: has personal loan? (binary: \"yes\",\"no\")\n",
    "- **noise_1-20**: random noise columns (intentionally added to simulate real-world scenario)\n",
    "\n",
    "**output variable (desired target):**\n",
    "- y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "!wget -q https://raw.githubusercontent.com/Jihun-ust/ust-mail-557/main/NeuralNetwork/phpkIxskf.arff\n",
    "file_name = \"phpkIxskf.arff\"\n",
    "data, meta = arff.loadarff(file_name)\n",
    "df = pd.DataFrame(data)\n",
    "# Rename columns\n",
    "col_map = {\n",
    "    \"V1\": \"age\",\n",
    "    \"V2\": \"job\",\n",
    "    \"V3\": \"marital\",\n",
    "    \"V4\": \"education\",\n",
    "    \"V5\": \"default\",\n",
    "    \"V6\": \"balance\",\n",
    "    \"V7\": \"housing\",\n",
    "    \"V8\": \"loan\",\n",
    "    \"Class\": \"subscribed\"\n",
    "}\n",
    "\n",
    "cat_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan']\n",
    "\n",
    "df = df.rename(columns=col_map)\n",
    "df = df[col_map.values()]\n",
    "\n",
    "# Convert data types\n",
    "def decode_bytes(val):\n",
    "    if isinstance(val, (bytes, bytearray)):\n",
    "        try:\n",
    "            return val.decode('utf-8')  # decode to string\n",
    "        except:\n",
    "            return str(val)  # fallback to str\n",
    "    if isinstance(val, str) and val.startswith(\"b'\"):  # string that looks like b'...'\n",
    "        return val.strip(\"b'\").strip(\"'\")\n",
    "    return val\n",
    "\n",
    "df = df.applymap(decode_bytes)\n",
    "\n",
    "# Convert target (binary)\n",
    "df[\"subscribed\"] = df[\"subscribed\"].replace({\"1\": 1, \"2\": 0})\n",
    "\n",
    "# Intentional data tweeking (Educational purpose)\n",
    "# Add random noise columns\n",
    "np.random.seed(42)\n",
    "for i in range(20):\n",
    "    df[f\"noise_{i}\"] = np.random.randn(len(df))\n",
    "\n",
    "# Ensure numeric columns are numeric\n",
    "num_cols = list(set(df.columns) - set(cat_cols + ['subscribed']))\n",
    "df[num_cols] = df[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split\n",
    "Hold out 20% of data for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['subscribed'])\n",
    "y = df['subscribed']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (MLP - Default)\n",
    "A simple feedforward network (multi‑layer perceptron). More flexible but less interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('clf', MLPClassifier(hidden_layer_sizes=(16, 8)))\n",
    "])\n",
    "mlp.fit(X_train, y_train)\n",
    "probs_nn = mlp.predict_proba(X_test)[:,1]\n",
    "\n",
    "auc_nn = roc_auc_score(y_test, probs_nn)\n",
    "pr_nn = average_precision_score(y_test, probs_nn)\n",
    "brier_nn = brier_score_loss(y_test, probs_nn)\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    \"NN result\":{\n",
    "        \"roc_auc_score\": auc_nn,\n",
    "        \"average_precision_score\": pr_nn,\n",
    "        \"brier_score_loss\": brier_nn\n",
    "    }\n",
    "})\n",
    "\n",
    "display(result.round(3))\n",
    "\n",
    "# Training Loss curve\n",
    "clf = mlp.named_steps[\"clf\"]\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(clf.loss_curve_)\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\")\n",
    "plt.title(\"MLP training loss curve\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (MLP) - Hyperparameter Tuning\n",
    "A simple feedforward network (multi‑layer perceptron) with hyperparameter tunings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_op = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('clf', MLPClassifier(\n",
    "        hidden_layer_sizes=(16, 8),\n",
    "        activation='relu',      # 'relu', 'identity', 'logistic', 'tanh'\n",
    "        solver='adam',          # 'lbfgs', 'sgd', 'adam'\n",
    "        alpha=0.01,\n",
    "        batch_size=50,\n",
    "        learning_rate='adaptive',\n",
    "        max_iter=3000,\n",
    "        shuffle=True,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=50,\n",
    "        validation_fraction=0.2\n",
    "        ))\n",
    "])\n",
    "mlp_op.fit(X_train, y_train)\n",
    "probs_op = mlp_op.predict_proba(X_test)[:,1]\n",
    "\n",
    "auc_op = roc_auc_score(y_test, probs_op)\n",
    "pr_op = average_precision_score(y_test, probs_op)\n",
    "brier_op = brier_score_loss(y_test, probs_op)\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    \"NN result\":{\n",
    "        \"roc_auc_score\": auc_op,\n",
    "        \"average_precision_score\": pr_op,\n",
    "        \"brier_score_loss\": brier_op\n",
    "    }\n",
    "})\n",
    "\n",
    "display(result.round(3))\n",
    "\n",
    "# Training Loss curve\n",
    "clf_op = mlp_op.named_steps[\"clf\"]\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(clf_op.loss_curve_)\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\")\n",
    "plt.title(\"MLP training loss curve\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Default vs. Optimized\n",
    "- **ROC‑AUC** (ranking quality): How well the model ranks likely buyers above non-buyers. (higher=better)\n",
    "- **PR‑AUC** (precision‑recall for rare positives): How well the model finds true buyers among the top predictions when buyers are rare. (higher=better)\n",
    "- **Brier score** (calibration): How well the predicted probabilities match reality (calibration). (lower=better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "fpr_nn, tpr_nn, _ = roc_curve(y_test, probs_nn)\n",
    "fpr_op, tpr_op, _ = roc_curve(y_test, probs_op)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr_nn, tpr_nn, label=f\"Neural Net (AUC={auc_nn:.3f})\")\n",
    "plt.plot(fpr_op, tpr_op, label=f\"Neural Net(Op) (AUC={auc_op:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--', color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall curves\n",
    "prec_nn, rec_nn, _ = precision_recall_curve(y_test, probs_nn)\n",
    "prec_op, rec_op, _ = precision_recall_curve(y_test, probs_op)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(rec_nn, prec_nn, label=f\"Neural Net (PR-AUC={pr_nn:.3f})\")\n",
    "plt.plot(rec_op, prec_op, label=f\"Neural Net(op) (PR-AUC={pr_op:.3f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve Comparison\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calibration (reliability) curve\n",
    "prob_true_nn, prob_pred_nn = calibration_curve(y_test, probs_nn, n_bins=12, strategy='quantile')\n",
    "prob_true_op, prob_pred_op = calibration_curve(y_test, probs_op, n_bins=12, strategy='quantile')\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(prob_pred_nn, prob_true_nn, label=f\"Neural Net (Brier={brier_nn:.3f})\")\n",
    "plt.plot(prob_pred_op, prob_true_op, label=f\"Neural Net(Op) (Brier={brier_op:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"Predicted probability (bin mean)\")\n",
    "plt.ylabel(\"Observed frequency\")\n",
    "plt.title(\"Calibration\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Neural Net\": {\n",
    "        \"ROC-AUC (higher=better)\": auc_nn,\n",
    "        \"PR-AUC (higher=better)\": pr_nn,\n",
    "        \"Brier (lower=better)\": brier_nn\n",
    "    },\n",
    "    \"Neural Net(Op)\": {\n",
    "        \"ROC-AUC (higher=better)\": auc_op,\n",
    "        \"PR-AUC (higher=better)\": pr_op,\n",
    "        \"Brier (lower=better)\": brier_op\n",
    "    }\n",
    "})\n",
    "\n",
    "display(results.T.round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
