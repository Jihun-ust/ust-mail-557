{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f22eb251",
   "metadata": {},
   "source": [
    "\n",
    "# Human Activity Recognition — Comparing Feedforward NN vs RNN vs LSTM vs GRU\n",
    "\n",
    "Train and compare four neural architectures on a real sequential task — smartphone-based **Human Activity Recognition (HAR)** — and visualize what leaders should look for at every step: data quality, leakage checks, baselines, learning curves, confusion matrices, generalization, model size/latency, and trade-offs.\n",
    "\n",
    "**Models compared**\n",
    "- **Feedforward NN (MLP)** on flattened sequences (ignores temporal order).\n",
    "- **SimpleRNN** (vanilla recurrent layer).\n",
    "- **LSTM** (handles long-term dependencies via gates).\n",
    "- **GRU** (gated, often smaller/faster than LSTM).\n",
    "\n",
    "**Dataset (public):** UCI *Human Activity Recognition Using Smartphones* (UCI HAR). It contains tri-axial accelerometer and gyroscope signals for six activities (Walking, Upstairs, Downstairs, Sitting, Standing, Laying). We will use the **Inertial Signals** windows (length 128) as proper sequences: shape `(samples, time_steps=128, channels=9)`.\n",
    "\n",
    "> If the dataset cannot be downloaded in your environment, this notebook will **fall back to a synthetic dataset** so you can still run the full workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b1848e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3f3036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, zipfile, io, urllib.request, shutil, time, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt, warnings\n",
    "\n",
    "# For modeling\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# For metrics and plots\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score, \n",
    "    balanced_accuracy_score, precision_score, recall_score,\n",
    "    f1_score, cohen_kappa_score, matthews_corrcoef, log_loss\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(7)\n",
    "tf.random.set_seed(7)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"Pandas:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6396f21",
   "metadata": {},
   "source": [
    "\n",
    "## Load the UCI HAR Dataset (with fallbacks)\n",
    "\n",
    "Try multiple official/mirrored URLs. If download fails (e.g., no internet, firewalls), we generate a **synthetic** dataset with similar shape and class balance so the rest of the notebook still runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac8d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"data_uci_har\")\n",
    "HAR_DIR = DATA_DIR / \"UCI HAR Dataset\"\n",
    "\n",
    "def try_download_uci_har(dest_dir: Path) -> bool:\n",
    "    dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # Several known URLs (first is the classic direct file)\n",
    "    urls = [\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\",\n",
    "        # New UCI site may require manual fetch; this is kept as a reference.\n",
    "        # If the first link fails, users can download manually from UCI and place here.\n",
    "        # \"https://archive.ics.uci.edu/dataset/240/human%2Bactivity%2Brecognition%2Busing%2Bsmartphones\"\n",
    "    ]\n",
    "    for url in urls:\n",
    "        try:\n",
    "            print(\"Attempting download:\", url)\n",
    "            with urllib.request.urlopen(url, timeout=60) as resp:\n",
    "                data = resp.read()\n",
    "            with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
    "                zf.extractall(dest_dir)\n",
    "            print(\"Downloaded & extracted to:\", dest_dir.resolve())\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(\"Download failed from\", url, \"->\", e)\n",
    "    print(\"\\nManual option: Download 'UCI HAR Dataset.zip' from the UCI page and unzip into:\", dest_dir.resolve())\n",
    "    return False\n",
    "\n",
    "def load_inertial_har(base: Path):\n",
    "    # Load 9 channels (body_acc, body_gyro, total_acc) each with x/y/z; each row has 128 time steps.\n",
    "    channels = [\n",
    "        \"body_acc_x\", \"body_acc_y\", \"body_acc_z\",\n",
    "        \"body_gyro_x\",\"body_gyro_y\",\"body_gyro_z\",\n",
    "        \"total_acc_x\",\"total_acc_y\",\"total_acc_z\"\n",
    "    ]\n",
    "    def load_split(split):\n",
    "        X_list = []\n",
    "        for ch in channels:\n",
    "            f = base / split / \"Inertial Signals\" / f\"{ch}_{split}.txt\"\n",
    "            arr = np.loadtxt(f)  # shape (n_samples, 128)\n",
    "            X_list.append(arr[:, :, None])  # (n, 128, 1)\n",
    "        X = np.concatenate(X_list, axis=2)  # (n, 128, 9)\n",
    "        y = np.loadtxt(base / split / f\"y_{split}.txt\").astype(int)  # labels 1..6\n",
    "        # Map to 0..5\n",
    "        y = y - 1\n",
    "        return X, y\n",
    "\n",
    "    X_train, y_train = load_split(\"train\")\n",
    "    X_test,  y_test  = load_split(\"test\")\n",
    "\n",
    "    # Activity labels per UCI HAR\n",
    "    activity_map = {\n",
    "        0: \"WALKING\",\n",
    "        1: \"WALKING_UPSTAIRS\",\n",
    "        2: \"WALKING_DOWNSTAIRS\",\n",
    "        3: \"SITTING\",\n",
    "        4: \"STANDING\",\n",
    "        5: \"LAYING\",\n",
    "    }\n",
    "    return X_train, y_train, X_test, y_test, activity_map\n",
    "\n",
    "download_ok = False\n",
    "if not HAR_DIR.exists():\n",
    "    download_ok = try_download_uci_har(DATA_DIR)\n",
    "else:\n",
    "    download_ok = True\n",
    "\n",
    "USE_SYNTHETIC = False\n",
    "if download_ok:\n",
    "    try:\n",
    "        X_train, y_train, X_test, y_test, activity_map = load_inertial_har(HAR_DIR)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to load inertial signals, falling back to synthetic. Error:\", e)\n",
    "        USE_SYNTHETIC = True\n",
    "else:\n",
    "    USE_SYNTHETIC = True\n",
    "\n",
    "if USE_SYNTHETIC:\n",
    "    print(\"Generating synthetic dataset with similar shape...\")\n",
    "    n_train, n_test = 6000, 2500\n",
    "    time_steps, channels, n_classes = 128, 9, 6\n",
    "    def make_synth(n):\n",
    "        # Class-specific sinusoids + noise to mimic different activities\n",
    "        X = np.zeros((n, time_steps, channels), dtype=np.float32)\n",
    "        y = np.random.randint(0, n_classes, size=n)\n",
    "        t = np.linspace(0, 4*np.pi, time_steps)\n",
    "        for i in range(n):\n",
    "            cls = y[i]\n",
    "            base_freq = (cls + 1) * 0.4\n",
    "            sig = np.sin(base_freq * t)[None, :].T  # (128,1)\n",
    "            noise = 0.3 * np.random.randn(time_steps, channels)\n",
    "            X[i] = sig @ np.ones((1, channels)) + noise\n",
    "        return X, y\n",
    "    X_train, y_train = make_synth(n_train)\n",
    "    X_test,  y_test  = make_synth(n_test)\n",
    "    activity_map = {i: f\"CLASS_{i}\" for i in range(6)}\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "time_steps = X_train.shape[1]\n",
    "channels   = X_train.shape[2]\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \" Test shape:\", X_test.shape)\n",
    "print(\"Classes:\", n_classes, activity_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dbc333",
   "metadata": {},
   "source": [
    "\n",
    "## Explore data and visualize sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9413391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "def plot_class_counts(y, title):\n",
    "    counts = pd.Series(y).value_counts().sort_index()\n",
    "    labels = [f\"{i}:{activity_map[i]}\" for i in counts.index]\n",
    "    plt.figure(figsize=(8,3.5)); plt.bar(labels, counts.values)\n",
    "    plt.title(title); plt.ylabel(\"count\"); plt.xticks(rotation=30, ha='right'); plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_class_counts(y_train, \"Train Class Distribution\")\n",
    "plot_class_counts(y_test,  \"Test Class Distribution\")\n",
    "\n",
    "# Plot a few example windows (first two channels only for readability)\n",
    "def plot_example_sequences(X, y, n=6):\n",
    "    idxs = np.random.choice(len(X), size=n, replace=False)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, idx in enumerate(idxs, 1):\n",
    "        ax = plt.subplot(n, 1, i)\n",
    "        ax.plot(X[idx, :, 0], label=\"ch0\")\n",
    "        ax.plot(X[idx, :, 1], label=\"ch1\")\n",
    "        ax.set_ylabel(f\"{activity_map[int(y[idx])]}\")\n",
    "        if i == 1: ax.legend(loc='upper right')\n",
    "    plt.xlabel(\"time step\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_example_sequences(X_train, y_train, n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d5314",
   "metadata": {},
   "source": [
    "\n",
    "## Train/Validation split and preprocessing\n",
    "\n",
    "Keep the dataset’s **pre-defined test set** (different subjects) and split the training set into train/validation. Standardize each channel by the **training** mean/std to avoid leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276dfe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Val split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=7)\n",
    "\n",
    "# Standardize per-channel using training statistics only\n",
    "mu = X_tr.mean(axis=(0,1), keepdims=True)\n",
    "sd = X_tr.std(axis=(0,1), keepdims=True) + 1e-8\n",
    "X_tr  = (X_tr  - mu) / sd\n",
    "X_val = (X_val - mu) / sd\n",
    "X_te  = (X_test - mu) / sd\n",
    "\n",
    "print(\"Standardized shapes:\", X_tr.shape, X_val.shape, X_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff5945",
   "metadata": {},
   "source": [
    "\n",
    "## Baselines\n",
    "\n",
    "- **Majority class** accuracy\n",
    "- **Feedforward NN (MLP)** on flattened sequences (order-less baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4586360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority baseline\n",
    "majority_class = pd.Series(y_tr).mode()[0]\n",
    "maj_acc = np.mean(y_test == majority_class)\n",
    "print(\"Majority-class baseline accuracy (on Test):\", round(float(maj_acc), 4))\n",
    "\n",
    "# Prepare one-hot labels for Keras\n",
    "def to_onehot(y, n_classes):\n",
    "    Y = np.zeros((len(y), n_classes), dtype=np.float32)\n",
    "    Y[np.arange(len(y)), y] = 1.0\n",
    "    return Y\n",
    "\n",
    "Y_tr, Y_val, Y_te = to_onehot(y_tr, n_classes), to_onehot(y_val, n_classes), to_onehot(y_test, n_classes)\n",
    "\n",
    "# Flattened inputs for MLP\n",
    "X_tr_flat = X_tr.reshape((X_tr.shape[0], -1))\n",
    "X_val_flat = X_val.reshape((X_val.shape[0], -1))\n",
    "X_te_flat  = X_te.reshape((X_te.shape[0],  -1))\n",
    "\n",
    "def build_mlp(input_dim, n_classes):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(n_classes, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "mlp = build_mlp(X_tr_flat.shape[1], n_classes)\n",
    "mlp.summary()\n",
    "\n",
    "cb = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, monitor=\"val_accuracy\")]\n",
    "hist_mlp = mlp.fit(X_tr_flat, Y_tr, validation_data=(X_val_flat, Y_val),\n",
    "                   epochs=30, batch_size=128, verbose=2, callbacks=cb)\n",
    "mlp_test_loss, mlp_test_acc = mlp.evaluate(X_te_flat, Y_te, verbose=0)\n",
    "print(\"MLP Test Acc:\", round(float(mlp_test_acc), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8e272d",
   "metadata": {},
   "source": [
    "\n",
    "## Recurrent models: SimpleRNN, LSTM, GRU\n",
    "Train three sequential models with similar capacity and compare.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631f9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_recurrent(kind:str, time_steps:int, channels:int, n_classes:int, units:int=64):\n",
    "    model = keras.Sequential([layers.Input(shape=(time_steps, channels))])\n",
    "    if kind == \"rnn\":\n",
    "        model.add(layers.SimpleRNN(units, return_sequences=False))\n",
    "    elif kind == \"lstm\":\n",
    "        model.add(layers.LSTM(units, return_sequences=False))\n",
    "    elif kind == \"gru\":\n",
    "        model.add(layers.GRU(units, return_sequences=False))\n",
    "    else:\n",
    "        raise ValueError(\"Unknown kind\")\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(layers.Dense(n_classes, activation=\"softmax\"))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "results = []\n",
    "histories = {}\n",
    "\n",
    "for kind in [\"rnn\", \"lstm\", \"gru\"]:\n",
    "    print(\"\\nTraining\", kind.upper(), \"…\")\n",
    "    model = build_recurrent(kind, time_steps, channels, n_classes, units=64)\n",
    "    model.summary()\n",
    "    cb = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, monitor=\"val_accuracy\")]\n",
    "    hist = model.fit(X_tr, Y_tr, validation_data=(X_val, Y_val),\n",
    "                     epochs=30, batch_size=128, verbose=2, callbacks=cb)\n",
    "    test_loss, test_acc = model.evaluate(X_te, Y_te, verbose=0)\n",
    "    results.append({\"model\": kind.upper(), \"test_acc\": float(test_acc), \"params\": model.count_params()})\n",
    "    histories[kind] = hist.history\n",
    "\n",
    "# Add MLP results too\n",
    "results.append({\"model\": \"MLP\", \"test_acc\": float(mlp_test_acc), \"params\": mlp.count_params()})\n",
    "res_df = pd.DataFrame(results).sort_values(\"test_acc\", ascending=False).reset_index(drop=True)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c443759",
   "metadata": {},
   "source": [
    "\n",
    "## Learning curves & capacity vs. accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b8580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(hist_dict, title):\n",
    "    plt.figure(figsize=(9,4))\n",
    "    for name, hist in hist_dict.items():\n",
    "        plt.plot(hist[\"val_accuracy\"], label=f\"{name.upper()} val_acc\")\n",
    "    plt.title(title); plt.xlabel(\"epoch\"); plt.ylabel(\"val_acc\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Histories include only RNN/LSTM/GRU; fetch MLP from its Keras History object\n",
    "hist_dict = histories.copy()\n",
    "hist_dict[\"mlp\"] = {\"val_accuracy\": [float(x) for x in (globals().get(\"hist_mlp\").history.get(\"val_accuracy\", []))]}\n",
    "plot_learning_curves(hist_dict, \"Validation Accuracy per Epoch\")\n",
    "\n",
    "# Params vs accuracy\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.scatter(res_df[\"params\"], res_df[\"test_acc\"])\n",
    "for i, r in res_df.iterrows():\n",
    "    plt.text(r[\"params\"], r[\"test_acc\"], r[\"model\"], fontsize=9, ha=\"left\", va=\"bottom\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Parameter count (log scale)\")\n",
    "plt.ylabel(\"Test accuracy\")\n",
    "plt.title(\"Capacity vs. Accuracy\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de2df33",
   "metadata": {},
   "source": [
    "\n",
    "## Confusion matrices & per-class metrics\n",
    "\n",
    "Compute predictions from the best-performing model and visualize the confusion matrix and class-wise precision/recall/F1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d944ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best model by test_acc\n",
    "best_name = res_df.iloc[0][\"model\"]\n",
    "print(\"Best model:\", best_name)\n",
    "\n",
    "def get_model_by_name(name):\n",
    "    if name == \"MLP\":\n",
    "        return mlp, lambda X: X.reshape((X.shape[0], -1))\n",
    "    k = name.lower()\n",
    "    # Rebuild and re-train is wasteful; instead, we kept the last trained instances in memory.\n",
    "    # We'll re-train quickly to obtain the trained instance when needed (simple approach for clarity).\n",
    "    model = build_recurrent(k, time_steps, channels, n_classes, units=64)\n",
    "    cb = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, monitor=\"val_accuracy\")]\n",
    "    _ = model.fit(X_tr, Y_tr, validation_data=(X_val, Y_val), epochs=30, batch_size=128, verbose=0, callbacks=cb)\n",
    "    if k in (\"rnn\",\"lstm\",\"gru\"):\n",
    "        return model, lambda X: X\n",
    "    raise ValueError(\"Unknown model name\")\n",
    "\n",
    "best_model, X_mapper = get_model_by_name(best_name)\n",
    "Xte_in = X_mapper(X_te)\n",
    "Y_pred = best_model.predict(Xte_in, batch_size=256, verbose=0)\n",
    "y_pred = Y_pred.argmax(axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=[activity_map[i] for i in range(n_classes)]))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "im = ax.imshow(cm, interpolation='nearest')\n",
    "ax.set_title(f\"Confusion Matrix — {best_name}\")\n",
    "ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
    "ax.set_xticks(range(n_classes)); ax.set_yticks(range(n_classes))\n",
    "ax.set_xticklabels([activity_map[i] for i in range(n_classes)], rotation=45, ha='right')\n",
    "ax.set_yticklabels([activity_map[i] for i in range(n_classes)])\n",
    "for i in range(n_classes):\n",
    "    for j in range(n_classes):\n",
    "        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", fontsize=8)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03124818",
   "metadata": {},
   "source": [
    "## Metrics beyond accuracy: Show they tell a consistent story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0082f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a trained model instance by name (retrain quickly to ensure availability)\n",
    "def _get_model_by_name(name:str):\n",
    "    global mlp  # from earlier section\n",
    "    if name.upper() == \"MLP\":\n",
    "        # uses flattened inputs\n",
    "        def mapper(X): return X.reshape((X.shape[0], -1))\n",
    "        return mlp, mapper, False\n",
    "    # recurrent models use (time, channels)\n",
    "    k = name.lower()\n",
    "    model = build_recurrent(k, time_steps, channels, n_classes, units=64)\n",
    "    cb = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, monitor=\"val_accuracy\")]\n",
    "    _ = model.fit(X_tr, Y_tr, validation_data=(X_val, Y_val),\n",
    "                  epochs=30, batch_size=128, verbose=0, callbacks=cb)\n",
    "    return model, (lambda X: X), True\n",
    "\n",
    "def evaluate_model(model, X, y_true):\n",
    "    \"\"\"Return a dict of metrics using predicted probabilities (for log_loss) and labels.\"\"\"\n",
    "    # Probabilities and labels\n",
    "    prob = model.predict(X, batch_size=256, verbose=0)\n",
    "    y_pred = prob.argmax(axis=1)\n",
    "\n",
    "    # Metrics\n",
    "    out = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        \"precision_macro\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"precision_weighted\": precision_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"recall_macro\": recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"recall_weighted\": recall_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\"),\n",
    "        \"f1_weighted\": f1_score(y_true, y_pred, average=\"weighted\"),\n",
    "        \"cohen_kappa\": cohen_kappa_score(y_true, y_pred),\n",
    "        \"mcc\": matthews_corrcoef(y_true, y_pred),\n",
    "        \"log_loss\": log_loss(y_true, prob)\n",
    "    }\n",
    "    return out\n",
    "\n",
    "model_names = [\"MLP\", \"RNN\", \"LSTM\", \"GRU\"]\n",
    "rows = []\n",
    "\n",
    "for name in model_names:\n",
    "    print(f\"Scoring {name} …\")\n",
    "    model, mapper, retrained = _get_model_by_name(name)\n",
    "    Xte_in = mapper(X_te)\n",
    "    metrics = evaluate_model(model, Xte_in, y_test)\n",
    "    metrics[\"model\"] = name\n",
    "    metrics[\"params\"] = model.count_params()\n",
    "    rows.append(metrics)\n",
    "\n",
    "metrics_df = pd.DataFrame(rows).set_index(\"model\")\n",
    "# Sort by macro-F1 (safer under imbalance) to emphasize consistency with accuracy\n",
    "metrics_df = metrics_df.sort_values(\"f1_macro\", ascending=False)\n",
    "display(metrics_df)\n",
    "\n",
    "# Correlation matrix to show the metrics largely agree (high positive correlations)\n",
    "corr = metrics_df.drop(columns=[\"params\", \"log_loss\"]).corr()\n",
    "print(\"\\nMetric correlation matrix (excluding params & log_loss):\")\n",
    "display(corr)\n",
    "\n",
    "# Plot: Accuracy vs Macro-F1\n",
    "print(\"Note: Accuracy vs Macro-F1 - Models should lie close to diagonal if they tell the same story.\")\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(metrics_df[\"accuracy\"], metrics_df[\"f1_macro\"])\n",
    "for m, r in metrics_df.iterrows():\n",
    "    plt.text(r[\"accuracy\"], r[\"f1_macro\"], m, fontsize=9, ha=\"left\", va=\"bottom\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"F1 (Macro)\")\n",
    "plt.title(\"Do Accuracy and F1 (Macro) agree?\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Capacity vs multiple metrics: overlay text for quick scan (optional)\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(metrics_df[\"params\"], metrics_df[\"f1_macro\"])\n",
    "for m, r in metrics_df.iterrows():\n",
    "    plt.text(r[\"params\"], r[\"f1_macro\"], f\"{m}\", fontsize=9, ha=\"left\", va=\"bottom\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Parameter count (log scale)\")\n",
    "plt.ylabel(\"F1 (Macro)\")\n",
    "plt.title(\"Capacity vs F1 (Macro)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Quick narrative check\n",
    "rank_cols = [\"accuracy\",\"balanced_accuracy\",\"f1_macro\",\"f1_weighted\",\"precision_macro\",\"recall_macro\",\"cohen_kappa\",\"mcc\"]\n",
    "ranks = metrics_df[rank_cols].rank(ascending=False, method=\"min\")\n",
    "print(\"\\nModel ranks across metrics (1 = best). Lower is better:\")\n",
    "display(ranks)\n",
    "print(\"\\nIf ranks are similar across columns, different metrics are not telling a different story here.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430279b8",
   "metadata": {},
   "source": [
    "## References\n",
    "- UCI Machine Learning Repository — *Human Activity Recognition Using Smartphones* (HAR).  \n",
    "  https://archive.ics.uci.edu/dataset/240/human%2Bactivity%2Brecognition%2Busing%2Bsmartphones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ust-mail (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
