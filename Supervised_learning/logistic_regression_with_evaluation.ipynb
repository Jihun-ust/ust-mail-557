{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2804232",
   "metadata": {},
   "source": [
    "\n",
    "# Logistic Regression – Binary Classification with Evaluation Metrics\n",
    "\n",
    "This notebook demonstrates a simple **Logistic Regression** model for binary classification.\n",
    "- Train a model on synthetic data\n",
    "- Predict labels on a test set\n",
    "- Evaluate performance using:\n",
    "  - Confusion Matrix\n",
    "  - Accuracy, Precision, Recall, F1 Score\n",
    "  - Visual summary of these metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary classification dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=500, n_features=4, n_informative=3, n_redundant=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338706b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7da03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "# Extract scores for visualization\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "metrics = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Score': [acc, prec, rec, f1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c23e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot evaluation metrics\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x='Metric', y='Score', data=metrics, palette='viridis')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.title(\"Evaluation Metrics – Logistic Regression\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84210fa6",
   "metadata": {},
   "source": [
    "\n",
    "## Interpretation & Insights\n",
    "\n",
    "- **Confusion Matrix**: Shows how many predictions were correct (diagonal) vs. incorrect (off-diagonal).\n",
    "- **Accuracy**: Overall correctness of the model.\n",
    "- **Precision**: How many predicted positives were actually correct.\n",
    "- **Recall**: How well the model captures all actual positives.\n",
    "- **F1 Score**: Harmonic mean of precision and recall — useful when classes are imbalanced.\n",
    "\n",
    "> If **precision is high** and **recall is low**, the model is conservative (avoids false positives).  \n",
    "> If **recall is high** but **precision is low**, the model is aggressive (catches more positives but with false alarms).\n",
    "\n",
    "This helps guide decisions about **threshold tuning**, **model adjustments**, or **business risk tolerance**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
