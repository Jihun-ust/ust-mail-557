{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc2737a",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Models (EM)\n",
    "\n",
    "Fit GMMs with varying components and covariance types, select by BIC/AIC, and inspect soft assignments (responsibilities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, warnings\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "!wget -q https://raw.githubusercontent.com/Jihun-ust/ust-mail-557/main/Unsupervised/unsup_utils.py.py\n",
    "import unsup_utils as utils\n",
    "csv_path = \"https://raw.githubusercontent.com/Jihun-ust/ust-mail-557/main/Unsupervised/unsup.csv\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "X, cols, sc = utils.feature_matrix(df, use_emb=True)\n",
    "\n",
    "components = list(range(2,9))\n",
    "cov_types = [\"full\",\"tied\",\"diag\",\"spherical\"]\n",
    "results = []\n",
    "\n",
    "for cov in cov_types:\n",
    "    bics, aics = [], []\n",
    "    for k in components:\n",
    "        gmm = GaussianMixture(n_components=k, covariance_type=cov, n_init=3, random_state=42)\n",
    "        gmm.fit(X)\n",
    "        bics.append(gmm.bic(X)); aics.append(gmm.aic(X))\n",
    "    results.append((cov, bics, aics))\n",
    "    plt.figure(figsize=(8,3.5)); plt.plot(components, bics, marker=\"o\"); plt.title(f\"BIC â€” {cov}\"); plt.xlabel(\"components\"); plt.ylabel(\"BIC\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "# choose the best overall by min BIC\n",
    "best = None; best_val = 1e18\n",
    "for cov, bics, aics in results:\n",
    "    k = components[int(np.argmin(bics))]; val = np.min(bics)\n",
    "    if val < best_val: best_val, best = val, (cov, k)\n",
    "\n",
    "print(\"Best by BIC:\", best)\n",
    "cov, k = best\n",
    "gmm = GaussianMixture(n_components=k, covariance_type=cov, n_init=5, random_state=42)\n",
    "df[\"cluster_gmm\"] = gmm.fit_predict(X)\n",
    "resp = gmm.predict_proba(X)  # responsibilities\n",
    "\n",
    "# Visualize in PCA space\n",
    "X2, p = utils.pca_2d(X)\n",
    "utils.plot_xy(X2, title=\"PCA (colored by GMM clusters)\", labels=df[\"cluster_gmm\"].values)\n",
    "\n",
    "# Soft confidence\n",
    "df[\"gmm_max_prob\"] = resp.max(axis=1)\n",
    "df[\"gmm_low_conf\"] = (df[\"gmm_max_prob\"] < 0.6).astype(int)\n",
    "df[[\"gmm_max_prob\",\"gmm_low_conf\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae0f91a",
   "metadata": {},
   "source": [
    "### Quick review: alignment to doc_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eba3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['cluster_gmm'], df['doc_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da49a62",
   "metadata": {},
   "source": [
    "### (Optional) Model Deep Dive\n",
    "- Automated BIC/AIC method alone may not yield the most meaningful GMM solution. In this case, five clusters with full covariance can offer clearer structure, with one cluster potentially capturing anomalies, highlighting the need to revisit the raw data for interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb77a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_best = ('full', 5)\n",
    "print(\"Another Possible Best:\", custom_best)\n",
    "cov, k = custom_best\n",
    "gmm = GaussianMixture(n_components=k, covariance_type=cov, n_init=5, random_state=42)\n",
    "df[\"cluster_gmm\"] = gmm.fit_predict(X)\n",
    "resp = gmm.predict_proba(X)\n",
    "\n",
    "# Visualize in PCA space\n",
    "X2, p = utils.pca_2d(X)\n",
    "utils.plot_xy(X2, title=\"PCA (colored by GMM clusters)\", labels=df[\"cluster_gmm\"].values)\n",
    "\n",
    "pd.crosstab(df['cluster_gmm'], df['doc_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db5e573",
   "metadata": {},
   "source": [
    "### BIC alone may not yield the most meaningful GMM solution\n",
    "Note: In Gaussian Mixture Models, the selection of cluster number and covariance structure based solely on the Bayesian Information Criterion (BIC) does not necessarily guarantee the most appropriate or interpretable solution. In the present example, a specification with five clusters under a full covariance structure yields results that appear more coherent (see BIC-full chart above).\n",
    "\n",
    "In particular, the fourth cluster may be interpreted as capturing outlier observations or anomalous patterns. This underscores the importance of complementing model selection criteria with substantive examination of the original data, in order to determine whether such clusters reflect meaningful structure, rare but informative cases, or potential data irregularities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
