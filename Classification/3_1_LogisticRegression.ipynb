{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1184f1f3",
   "metadata": {},
   "source": [
    "# Logistic Regression (Binary & Multinomial)\n",
    "\n",
    "**Scenario**: Lead qualification, predict whether a marketing lead will convert.\n",
    "\n",
    "Use a chronological split, evaluate ROC/PR, pick an operating threshold, and calibrate probabilities.\n",
    "\n",
    "Diagnostics\n",
    "- Base rate & class balance\n",
    "- PR‑AUC / ROC‑AUC + calibration curves\n",
    "- Thresholds, confusion matrix & expected‑value rationale\n",
    "- Top coefficients with odds‑ratio translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71203f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "!wget -q https://raw.githubusercontent.com/Jihun-ust/ust-mail-557/main/Classification/classification_utils.py\n",
    "import classification_utils as utils\n",
    "csv_path = \"https://raw.githubusercontent.com/Jihun-ust/ust-mail-557/main/Classification/classification.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path, parse_dates=[\"ts\"]).sort_values(\"ts\")\n",
    "train, test = utils.chrono_split(df, \"ts\", test_frac=0.2)\n",
    "\n",
    "features = [\"ad_channel\",\"device\",\"region\",\"campaign\",\"spend_l7\",\"pages_per_session\",\"sessions_l30\",\"time_on_site_s\",\"pricing_views_l7\",\"email_opens_l30\",\"past_purchases\",\"tenure_days\",\"discount_flag\",\"competitor_visits\"]\n",
    "target = \"converted\"\n",
    "\n",
    "X_train, y_train = train[features], train[target]\n",
    "X_test, y_test = test[features], test[target]\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), [\"spend_l7\",\"pages_per_session\",\"sessions_l30\",\"time_on_site_s\",\"pricing_views_l7\",\"email_opens_l30\",\"past_purchases\",\"tenure_days\"]),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"ad_channel\",\"device\",\"region\",\"campaign\"]),\n",
    "    (\"bin\", \"passthrough\", [\"discount_flag\",\"competitor_visits\"])\n",
    "])\n",
    "\n",
    "clf = Pipeline([(\"pre\", pre), (\"lr\", LogisticRegression(max_iter=500, class_weight=None))])\n",
    "clf.fit(X_train, y_train)\n",
    "probs = clf.predict_proba(X_test)[:,1]\n",
    "print(\"Log loss:\", log_loss(y_test, probs))\n",
    "metrics = utils.evaluate_classifier(y_test, probs, threshold=0.5, title_prefix=\"Logistic (baseline)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a0c572",
   "metadata": {},
   "source": [
    "### Advanced Diagnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddb71d0",
   "metadata": {},
   "source": [
    "#### Base rate & class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balance(y):\n",
    "    y = pd.Series(y)\n",
    "    return pd.DataFrame({\n",
    "        \"count\": y.value_counts(),\n",
    "        \"rate\": y.value_counts(normalize=True)\n",
    "    }).rename_axis(\"class\").reset_index()\n",
    "\n",
    "cb_train = class_balance(y_train)\n",
    "cb_test  = class_balance(y_test)\n",
    "\n",
    "print(\"Train set\")\n",
    "display(pd.DataFrame({\"split\":[\"train\"]*len(cb_train), **cb_train.to_dict(\"list\")}))\n",
    "print(\"Test set\")\n",
    "display(pd.DataFrame({\"split\":[\"test\"]*len(cb_test),  **cb_test.to_dict(\"list\")}))\n",
    "\n",
    "# Quick bar: positive class rate over time (optional)\n",
    "if \"ts\" in test.columns:\n",
    "    tmp = test[[\"ts\", target]].copy()\n",
    "    tmp[\"week\"] = tmp[\"ts\"].dt.to_period(\"W\").dt.to_timestamp()\n",
    "    agg = tmp.groupby(\"week\")[target].mean().reset_index()\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.plot(agg[\"week\"], agg[target], marker=\"o\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(\"Weekly positive rate (test)\")\n",
    "    plt.xlabel(\"week\"); plt.ylabel(\"P(y=1)\")\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5faa04",
   "metadata": {},
   "source": [
    "#### PR‑AUC / ROC‑AUC + calibration curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed309e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test, probs)\n",
    "pr_auc  = average_precision_score(y_test, probs)\n",
    "print(f\"ROC‑AUC: {roc_auc:.3f} | PR‑AUC: {pr_auc:.3f}\")\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, roc_th = roc_curve(y_test, probs)\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
    "plt.plot([0,1],[0,1], linestyle=\"--\", linewidth=1)\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC curve\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# PR\n",
    "prec, rec, pr_th = precision_recall_curve(y_test, probs)\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.plot(rec, prec, label=f\"AP={pr_auc:.3f}\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision‑Recall curve\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Calibration curve (reliability)\n",
    "prob_true, prob_pred = calibration_curve(y_test, probs, n_bins=10, strategy=\"quantile\")\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.plot(prob_pred, prob_true, marker=\"o\", label=\"model\")\n",
    "plt.plot([0,1],[0,1], linestyle=\"--\", linewidth=1, label=\"perfect\")\n",
    "plt.xlabel(\"Predicted probability (bin avg)\")\n",
    "plt.ylabel(\"Observed frequency\")\n",
    "plt.title(\"Calibration curve (test)\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e72b53",
   "metadata": {},
   "source": [
    "#### Thresholds, confusion matrix & expected‑value rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df83d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate thresholds\n",
    "# t_f1: maximizes F1\n",
    "f1s = []\n",
    "grid = np.linspace(0.01, 0.99, 99)\n",
    "for t in grid:\n",
    "    yhat = (probs >= t).astype(int)\n",
    "    f1s.append(f1_score(y_test, yhat))\n",
    "t_f1 = float(grid[int(np.argmax(f1s))])\n",
    "\n",
    "# t_ks: Youden/KS (maximize TPR - FPR) on ROC\n",
    "tpr_m, fpr_m, th_m = tpr, fpr, roc_th\n",
    "ks_vals = tpr_m - fpr_m\n",
    "t_ks = float(th_m[int(np.argmax(ks_vals))])\n",
    "\n",
    "# t_cost: expected value threshold (set your economics here)\n",
    "# EV = TP * gain_tp - FP * cost_fp - FN * cost_fn - TN * cost_tn (defaults)\n",
    "gain_tp = 100.0   # e.g., expected profit if we act and a user converts\n",
    "cost_fp = 10.0    # e.g., cost of acting on a non‑converter\n",
    "cost_fn = 40.0    # e.g., opportunity cost of missing a converter\n",
    "cost_tn = 0.0     # cost of correctly not acting\n",
    "def expected_value(y_true, p, t, g_tp=gain_tp, c_fp=cost_fp, c_fn=cost_fn, c_tn=cost_tn):\n",
    "    yhat = (p >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, yhat).ravel()\n",
    "    return tp*g_tp - fp*c_fp - fn*c_fn - tn*c_tn\n",
    "\n",
    "evs = [expected_value(y_test, probs, t) for t in grid]\n",
    "t_cost = float(grid[int(np.argmax(evs))])\n",
    "\n",
    "print(f\"Proposed thresholds → F1-opt: {t_f1:.2f} | KS/Youden: {t_ks:.2f} | EV-opt: {t_cost:.2f}\")\n",
    "\n",
    "# Confusion matrices & EV at proposed thresholds\n",
    "def cm_report(y_true, p, t, label):\n",
    "    yhat = (p >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, yhat).ravel()\n",
    "    total = tn+fp+fn+tp\n",
    "    ev = expected_value(y_true, p, t)\n",
    "    print(f\"[{label}] thresh={t:.2f} | TP={tp} FP={fp} FN={fn} TN={tn} | \"\n",
    "          f\"TPR={tp/(tp+fn+1e-12):.3f} FPR={fp/(fp+tn+1e-12):.3f} Precision={tp/(tp+fp+1e-12):.3f} | EV={ev:,.2f}\")\n",
    "\n",
    "cm_report(y_test, probs, 0.50, \"Baseline 0.5\")\n",
    "cm_report(y_test, probs, t_f1, \"F1‑opt\")\n",
    "cm_report(y_test, probs, t_ks, \"KS/Youden\")\n",
    "cm_report(y_test, probs, t_cost, \"EV‑opt\")\n",
    "\n",
    "# Plot EV vs threshold\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(grid, evs)\n",
    "plt.axvline(t_cost, linestyle=\"--\")\n",
    "plt.xlabel(\"threshold\"); plt.ylabel(\"Expected value\")\n",
    "plt.title(\"Expected value vs threshold (test)\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31028ae",
   "metadata": {},
   "source": [
    "#### Top coefficients with odds‑ratio translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6dbe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(preprocessor, input_features):\n",
    "    \"\"\"Extract fully expanded feature names from ColumnTransformer + inner transformers.\"\"\"\n",
    "    out = []\n",
    "    for name, trans, cols in preprocessor.transformers_:\n",
    "        if name == \"remainder\" and trans == \"drop\":\n",
    "            continue\n",
    "        if hasattr(trans, \"get_feature_names_out\"):\n",
    "            # e.g., OneHotEncoder, Polynomial, etc.\n",
    "            fn = trans.get_feature_names_out(cols)\n",
    "        elif trans == \"passthrough\":\n",
    "            fn = np.array(cols)\n",
    "        else:\n",
    "            # StandardScaler or others without names_out: pass through column names\n",
    "            fn = np.array(cols)\n",
    "        out.extend(fn.tolist())\n",
    "    return np.array(out)\n",
    "\n",
    "# Pull LR from pipeline and map coefs to names\n",
    "assert isinstance(clf, Pipeline) and \"pre\" in clf.named_steps and \"lr\" in clf.named_steps\n",
    "lr: LogisticRegression = clf.named_steps[\"lr\"]\n",
    "preproc = clf.named_steps[\"pre\"]\n",
    "\n",
    "feat_names = get_feature_names(preproc, features)\n",
    "coef = lr.coef_.ravel()\n",
    "odds_ratio = np.exp(coef)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feat_names,\n",
    "    \"coef\": coef,\n",
    "    \"odds_ratio\": odds_ratio,\n",
    "}).sort_values(\"coef\", ascending=False)\n",
    "\n",
    "# Top positive & negative drivers\n",
    "top_k = 12\n",
    "top_pos = coef_df.head(top_k)\n",
    "top_neg = coef_df.tail(top_k).sort_values(\"coef\")\n",
    "\n",
    "print(f\"Top {top_k} Positive Drivers\")\n",
    "display(top_pos)\n",
    "print(f\"Top {top_k} Negative Drivers\")\n",
    "display(top_neg)\n",
    "\n",
    "# Quick text translation helper\n",
    "def plain_explain(row):\n",
    "    f = row[\"feature\"]\n",
    "    orv = row[\"odds_ratio\"]\n",
    "    if \"ad_channel_\" in f:\n",
    "        base = f.replace(\"ad_channel_\", \"\")\n",
    "        return f\"If ad_channel = '{base}', odds of conversion are ×{orv:.2f} vs baseline channel (holding others constant).\"\n",
    "    if \"device_\" in f:\n",
    "        base = f.replace(\"device_\", \"\")\n",
    "        return f\"Using device '{base}' multiplies conversion odds by ×{orv:.2f} vs the reference device.\"\n",
    "    if \"region_\" in f:\n",
    "        base = f.replace(\"region_\", \"\")\n",
    "        return f\"Region '{base}' changes conversion odds by ×{orv:.2f} vs the reference region.\"\n",
    "    if \"campaign_\" in f:\n",
    "        base = f.replace(\"campaign_\", \"\")\n",
    "        return f\"Campaign '{base}' changes conversion odds by ×{orv:.2f} vs the reference campaign.\"\n",
    "    if f in [\"discount_flag\",\"competitor_visits\"]:\n",
    "        return f\"Flag '{f}=1' multiplies odds by ×{orv:.2f} compared with {f}=0.\"\n",
    "    return f\"A one‑SD increase in '{f}' multiplies conversion odds by ×{orv:.2f}.\"\n",
    "\n",
    "print(\"\\nPlain-language explanations (sample):\")\n",
    "for _, r in pd.concat([top_pos.head(6), top_neg.head(6)]).iterrows():\n",
    "    print(\" •\", plain_explain(r))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Warning: The dataset used in this example was programmatically generated, which does not reflect real-world information.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
