{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3163210f",
   "metadata": {},
   "source": [
    "# Support Vector Machines (Linear & Kernel)\n",
    "\n",
    "Compare LinearSVC (with calibration) and RBF-kernel SVC. Scaling is critical; Also handle probability calibration where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, pandas as pd, numpy as np, matplotlib.pyplot as plt, warnings\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, brier_score_loss, confusion_matrix\n",
    "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
    "\n",
    "!wget -q https://raw.githubusercontent.com/Jihun-ust/ust-mail-557/main/Classification/classification_utils.py\n",
    "import classification_utils as utils\n",
    "csv_path = \"https://raw.githubusercontent.com/Jihun-ust/ust-mail-557/main/Classification/classification.csv\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv(csv_path, parse_dates=[\"ts\"]).sort_values(\"ts\")\n",
    "train, test = utils.chrono_split(df, \"ts\", test_frac=0.2)\n",
    "\n",
    "features = [\"ad_channel\",\"device\",\"region\",\"campaign\",\"spend_l7\",\"pages_per_session\",\"sessions_l30\",\"time_on_site_s\",\"pricing_views_l7\",\"past_purchases\",\"discount_flag\",\"competitor_visits\"]\n",
    "target = \"converted\"\n",
    "\n",
    "X_train, y_train = train[features], train[target]\n",
    "X_test, y_test = test[features], test[target]\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), [\"spend_l7\",\"pages_per_session\",\"sessions_l30\",\"time_on_site_s\",\"pricing_views_l7\",\"past_purchases\"]),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"ad_channel\",\"device\",\"region\",\"campaign\"]),\n",
    "    (\"bin\", \"passthrough\", [\"discount_flag\",\"competitor_visits\"])\n",
    "])\n",
    "\n",
    "# LinearSVC + calibration (no native predict_proba)\n",
    "lin = Pipeline([(\"pre\", pre), (\"svc\", LinearSVC(C=1.0, class_weight=None, random_state=42))])\n",
    "lin.fit(X_train, y_train)\n",
    "# Calibrate on a slice of the training set\n",
    "val = train.iloc[-5000:]\n",
    "cal_lin = CalibratedClassifierCV(lin, cv=\"prefit\", method=\"isotonic\")\n",
    "cal_lin.fit(val[features], val[target])\n",
    "probs_lin = cal_lin.predict_proba(X_test)[:,1]\n",
    "_ = utils.evaluate_classifier(y_test, probs_lin, title_prefix=\"LinearSVC (calibrated)\")\n",
    "\n",
    "# RBF SVC (native probas if probability=True; more expensive)\n",
    "rbf = Pipeline([(\"pre\", pre), (\"svc\", SVC(C=1.0, kernel=\"rbf\", gamma=\"scale\", probability=True, random_state=42))])\n",
    "rbf.fit(X_train, y_train)\n",
    "probs_rbf = rbf.predict_proba(X_test)[:,1]\n",
    "_ = utils.evaluate_classifier(y_test, probs_rbf, title_prefix=\"RBF SVC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c9d12",
   "metadata": {},
   "source": [
    "### High-level Report Review (Example)\n",
    "\n",
    "Compared two Support Vector Machine (SVM) models:\n",
    "   - Linear SVM: Assumes a straight-line boundary between converted vs. non-converted leads.\n",
    "   - RBF SVM: Uses a more flexible boundary that can curve to capture nonlinear patterns.\n",
    "\n",
    "Key results\n",
    "   - Overall accuracy: Both models are the same (~60%). Neither kernel improves the headline number.\n",
    "   - Converted leads (class 1): Both models are strong, with recall ~88–90%. That means they catch almost all of the leads who actually convert.\n",
    "   - Non-converted leads (class 0): Both models struggle. Recall is only ~16–20%, meaning most non-converting leads are still being misclassified as converters.\n",
    "   - Trade-off:\n",
    "      - Linear kernel → slightly worse on finding positives, slightly better on catching negatives.\n",
    "      - RBF kernel → slightly better on positives, but even weaker on negatives.\n",
    "\n",
    "Interpretation\n",
    "   - Both models over-favor predicting “converted”, which inflates recall for converters but misses too many non-converters.\n",
    "   - This is why accuracy stalls around 60%: the model isn’t learning enough structure in the data to separate the groups cleanly.\n",
    "   - The choice of kernel (linear vs. RBF) makes only a marginal difference here — the limitation is likely the data features, not the algorithm.\n",
    "\n",
    "Quick takeaway\n",
    "   - These models are good at ensuring we don’t “miss” potential converters, but they generate a lot of false positives (non-converters wrongly flagged as converters).\n",
    "   - For decision-making, this means marketing/sales resources may be over-allocated to leads who won’t convert.\n",
    "   - Possible improvements:\n",
    "      - Enrich the features (better signals of non-conversion).\n",
    "\t  - Rebalance the training (penalize misclassifying non-converters more heavily).\n",
    "\t  - Tune thresholds for different use-cases (e.g., prioritize precision if minimizing wasted effort is the goal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56172bb",
   "metadata": {},
   "source": [
    "#### (Advanced) Time-aware hyperparameter curves (C for Linear; C & γ for RBF)\n",
    "   - Uses TimeSeriesSplit to respect chronology. For group-aware validation (e.g., by campaign), swap in GroupKFold or PurgedGroupTimeSeriesSplit and pass groups=train[\"campaign\"].\n",
    "   \n",
    "   - **Warning**: Running this cell on Google Colab (free tire) can take over an hour. You're welcome to try it, but to save time the faster versions are provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-aware hyperparameter curves\n",
    "def time_aware_scores(pipe, X, y, Cs, gammas=None, kernel=\"linear\", metric=\"average_precision\", n_splits=5):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    scores = []\n",
    "\n",
    "    for C in Cs:\n",
    "        if kernel == \"linear\":\n",
    "            base = Pipeline([(\"pre\", pre), (\"svc\", LinearSVC(C=C, random_state=42))])\n",
    "            row = {\"C\": C, \"gamma\": np.nan}\n",
    "            row_scores = []\n",
    "            for tr_idx, va_idx in tscv.split(X, y):\n",
    "                base.fit(X.iloc[tr_idx], y.iloc[tr_idx])\n",
    "                # calibrate on the tail of training fold to avoid leakage\n",
    "                cal_slice = tr_idx[int(0.8*len(tr_idx)):]  # last 20% of train as calib\n",
    "                cal = CalibratedClassifierCV(base, cv=\"prefit\", method=\"isotonic\")\n",
    "                cal.fit(X.iloc[cal_slice], y.iloc[cal_slice])\n",
    "                p = cal.predict_proba(X.iloc[va_idx])[:,1]\n",
    "                s = average_precision_score(y.iloc[va_idx], p) if metric==\"average_precision\" else roc_auc_score(y.iloc[va_idx], p)\n",
    "                row_scores.append(s)\n",
    "            row[\"mean\"], row[\"std\"] = float(np.mean(row_scores)), float(np.std(row_scores))\n",
    "            scores.append(row)\n",
    "\n",
    "        elif kernel == \"rbf\":\n",
    "            assert gammas is not None\n",
    "            for g in gammas:\n",
    "                base = Pipeline([(\"pre\", pre), (\"svc\", SVC(C=C, gamma=g, kernel=\"rbf\", probability=True, random_state=42))])\n",
    "                row = {\"C\": C, \"gamma\": g}\n",
    "                row_scores = []\n",
    "                for tr_idx, va_idx in tscv.split(X, y):\n",
    "                    base.fit(X.iloc[tr_idx], y.iloc[tr_idx])\n",
    "                    p = base.predict_proba(X.iloc[va_idx])[:,1]\n",
    "                    s = average_precision_score(y.iloc[va_idx], p) if metric==\"average_precision\" else roc_auc_score(y.iloc[va_idx], p)\n",
    "                    row_scores.append(s)\n",
    "                row[\"mean\"], row[\"std\"] = float(np.mean(row_scores)), float(np.std(row_scores))\n",
    "                scores.append(row)\n",
    "\n",
    "    import pandas as pd\n",
    "    out = pd.DataFrame(scores)\n",
    "    return out\n",
    "\n",
    "Cs = [0.05, 0.1, 0.2, 0.5, 1, 2, 5]\n",
    "Gammas = [\"scale\", 0.05, 0.1, 0.2]  # modest grid; expand if compute budget allows\n",
    "\n",
    "lin_grid = time_aware_scores(lin, X_train, y_train, Cs=Cs, kernel=\"linear\", metric=\"average_precision\")\n",
    "rbf_grid = time_aware_scores(rbf, X_train, y_train, Cs=Cs, gammas=Gammas, kernel=\"rbf\", metric=\"average_precision\")\n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.errorbar(lin_grid[\"C\"], lin_grid[\"mean\"], yerr=lin_grid[\"std\"], marker=\"o\")\n",
    "plt.xscale(\"log\"); plt.ylim(0,1)\n",
    "plt.xlabel(\"C (log)\"); plt.ylabel(\"PR-AUC (mean±sd)\"); plt.title(\"LinearSVC (calibrated), Time-aware PR-AUC\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# For RBF, one curve per gamma\n",
    "plt.figure(figsize=(7,4))\n",
    "for g in rbf_grid[\"gamma\"].dropna().unique():\n",
    "    sub = rbf_grid[rbf_grid[\"gamma\"]==g].sort_values(\"C\")\n",
    "    lbl = f\"gamma={g}\"\n",
    "    plt.errorbar(sub[\"C\"], sub[\"mean\"], yerr=sub[\"std\"], marker=\"o\", label=lbl)\n",
    "plt.xscale(\"log\"); plt.ylim(0,1); plt.legend()\n",
    "plt.xlabel(\"C (log)\"); plt.ylabel(\"PR-AUC (mean±sd)\"); plt.title(\"RBF SVC, Time-aware PR-AUC\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5785732b",
   "metadata": {},
   "source": [
    "Fast version: LinearSVC time-aware PR-AUC vs C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e0135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast version: LinearSVC time-aware PR-AUC vs C (subsample + 3 folds + decision_function)\n",
    "t0 = time.time()\n",
    "\n",
    "# Chronology-preserving subsample (use earliest portion of the training horizon)\n",
    "frac = 0.30  # 30% of train; bump up if you have time\n",
    "n_sub = max(2000, int(len(X_train) * frac))\n",
    "X_sub, y_sub = X_train.iloc[:n_sub], y_train.iloc[:n_sub]\n",
    "\n",
    "Cs = [0.05, 0.1, 0.2, 0.5, 1, 2, 5]\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "scores_mean, scores_std = [], []\n",
    "\n",
    "for C in Cs:\n",
    "    fold_scores = []\n",
    "    for tr_idx, va_idx in tscv.split(X_sub, y_sub):\n",
    "        pipe = Pipeline([(\"pre\", pre), (\"svc\", LinearSVC(C=C, random_state=42))])\n",
    "        pipe.fit(X_sub.iloc[tr_idx], y_sub.iloc[tr_idx])\n",
    "        # Use decision_function for ranking; AP accepts real-valued scores\n",
    "        s = pipe.decision_function(X_sub.iloc[va_idx])\n",
    "        ap = average_precision_score(y_sub.iloc[va_idx], s)\n",
    "        fold_scores.append(ap)\n",
    "    scores_mean.append(np.mean(fold_scores))\n",
    "    scores_std.append(np.std(fold_scores))\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"[LinearSVC] Subsample n={n_sub}, folds=3, grid={Cs} → done in {elapsed:.1f}s\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.errorbar(Cs, scores_mean, yerr=scores_std, marker=\"o\")\n",
    "plt.xscale(\"log\"); plt.ylim(0,1)\n",
    "plt.xlabel(\"C (log scale)\"); plt.ylabel(\"PR-AUC (mean±sd)\")\n",
    "plt.title(\"LinearSVC, Time-aware PR-AUC vs C (fast)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Optional: pick best C and (re)fit with calibration only once on full train\n",
    "best_C = Cs[int(np.argmax(scores_mean))]\n",
    "print(\"Best C (fast search):\", best_C)\n",
    "lin_fast = Pipeline([(\"pre\", pre), (\"svc\", LinearSVC(C=best_C, random_state=42))]).fit(X_train, y_train)\n",
    "cal_lin_fast = CalibratedClassifierCV(lin_fast, cv=\"prefit\", method=\"isotonic\")\n",
    "cal_lin_fast.fit(train.iloc[-5000:][features], train.iloc[-5000:][target])\n",
    "probs_lin_fast = cal_lin_fast.predict_proba(X_test)[:,1]\n",
    "_ = utils.evaluate_classifier(y_test, probs_lin_fast, title_prefix=f\"LinearSVC C={best_C} (fast search, calibrated)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac3e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM — margin width vs C, support vectors vs C, accuracy vs C\n",
    "t0 = time.time()\n",
    "\n",
    "# Small, log-spaced C grid (tweak if you want denser curves)\n",
    "Cs = [0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10]\n",
    "\n",
    "margin_widths = []\n",
    "n_support      = []\n",
    "accs           = []\n",
    "\n",
    "for C in Cs:\n",
    "    # Use SVC(kernel=\"linear\") so we get both coef_ (for margin) and n_support_\n",
    "    model = Pipeline([(\"pre\", pre), (\"svc\", SVC(kernel=\"linear\", C=C, random_state=42))])\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    svc = model.named_steps[\"svc\"]\n",
    "    # Margin width = 2 / ||w||  (in the model's feature space after preprocessing)\n",
    "    w = svc.coef_.ravel()\n",
    "    m = 2.0 / (np.linalg.norm(w) + 1e-12)\n",
    "    margin_widths.append(m)\n",
    "\n",
    "    n_sv = int(svc.n_support_.sum())\n",
    "    n_support.append(n_sv)\n",
    "\n",
    "    acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    accs.append(acc)\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"[E1a] Done in {elapsed:.1f}s across {len(Cs)} C values.\")\n",
    "\n",
    "# Optional: numeric summary\n",
    "summary = pd.DataFrame({\"C\": Cs,\n",
    "                        \"margin_width\": margin_widths,\n",
    "                        \"n_support\": n_support,\n",
    "                        \"accuracy\": accs})\n",
    "display(summary)\n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(Cs, margin_widths, marker=\"o\")\n",
    "plt.xscale(\"log\"); plt.xlabel(\"C (log)\"); plt.ylabel(\"Margin width (2/||w||)\")\n",
    "plt.title(\"Linear SVM — Margin width vs C\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(Cs, n_support, marker=\"o\")\n",
    "plt.xscale(\"log\"); plt.xlabel(\"C (log)\"); plt.ylabel(\"# Support vectors\")\n",
    "plt.title(\"Linear SVM — Support vectors vs C\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(Cs, accs, marker=\"o\")\n",
    "plt.xscale(\"log\"); plt.xlabel(\"C (log)\"); plt.ylabel(\"Accuracy (test)\")\n",
    "plt.title(\"Linear SVM — Accuracy vs C\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11e5b15",
   "metadata": {},
   "source": [
    "Fast version: RBF SVC time-aware PR-AUC heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b74564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast version: RBF SVC time-aware PR-AUC heatmap (subsample + 3 folds + decision_function)\n",
    "t0 = time.time()\n",
    "\n",
    "# Reuse the same chronology-preserving subsample\n",
    "X_sub, y_sub = X_train.iloc[:n_sub], y_train.iloc[:n_sub]\n",
    "\n",
    "Cs = [0.5, 2.0]            # very small grid\n",
    "Gammas = [\"scale\", 0.2]    # keep tiny; swap/add values if you have budget\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "heat = np.zeros((len(Cs), len(Gammas)))\n",
    "for i, C in enumerate(Cs):\n",
    "    for j, g in enumerate(Gammas):\n",
    "        fold_scores = []\n",
    "        for tr_idx, va_idx in tscv.split(X_sub, y_sub):\n",
    "            pipe = Pipeline([(\"pre\", pre), (\"svc\", SVC(C=C, kernel=\"rbf\", gamma=g,\n",
    "                                                      probability=False, random_state=42))])\n",
    "            pipe.fit(X_sub.iloc[tr_idx], y_sub.iloc[tr_idx])\n",
    "            s = pipe.decision_function(X_sub.iloc[va_idx])  # scores for AP\n",
    "            ap = average_precision_score(y_sub.iloc[va_idx], s)\n",
    "            fold_scores.append(ap)\n",
    "        heat[i, j] = np.mean(fold_scores)\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"[RBF SVC] Subsample n={n_sub}, folds=3, grid={len(Cs)}x{len(Gammas)} → done in {elapsed:.1f}s\")\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(5.5,3.8))\n",
    "for (i,C) in enumerate(Cs):\n",
    "    for (j,g) in enumerate(Gammas):\n",
    "        plt.text(j, i, f\"{heat[i,j]:.3f}\", ha=\"center\", va=\"center\")\n",
    "plt.imshow(heat, aspect=\"auto\", origin=\"upper\", vmin=0, vmax=1)\n",
    "plt.colorbar(label=\"PR-AUC\")\n",
    "plt.xticks(range(len(Gammas)), [str(g) for g in Gammas])\n",
    "plt.yticks(range(len(Cs)), [str(c) for c in Cs])\n",
    "plt.xlabel(\"gamma\"); plt.ylabel(\"C\")\n",
    "plt.title(\"RBF SVC, Time-aware PR-AUC (fast)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Choose best (C,gamma) and refit once on full train with probability=True (for downstream needs)\n",
    "best_i, best_j = np.unravel_index(np.argmax(heat), heat.shape)\n",
    "best_C, best_g = Cs[best_i], Gammas[best_j]\n",
    "print(\"Best (C, gamma) from fast search:\", best_C, best_g)\n",
    "\n",
    "rbf_fast = Pipeline([(\"pre\", pre), (\"svc\", SVC(C=best_C, kernel=\"rbf\", gamma=best_g,\n",
    "                                               probability=True, random_state=42))]).fit(X_train, y_train)\n",
    "probs_rbf_fast = rbf_fast.predict_proba(X_test)[:,1]\n",
    "_ = utils.evaluate_classifier(y_test, probs_rbf_fast, title_prefix=f\"RBF SVC C={best_C}, γ={best_g} (fast search)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b32576e",
   "metadata": {},
   "source": [
    "#### Calibration curves (pre/post) with Brier score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50292d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration curves & Brier score\n",
    "# LinearSVC\n",
    "# PRE: use an uncalibrated decision_function -> map to [0,1] by rank (for curve shape only)\n",
    "lin_uncal = Pipeline([(\"pre\", pre), (\"svc\", LinearSVC(C=1.0, random_state=42))]).fit(X_train, y_train)\n",
    "dec_test = lin_uncal.decision_function(X_test)\n",
    "# normalize to [0,1] (not a true prob; for visual comparison only)\n",
    "p_lin_pre = (dec_test - dec_test.min()) / (dec_test.max() - dec_test.min() + 1e-12)\n",
    "\n",
    "# POST: use your calibrated linear\n",
    "p_lin_post = probs_lin\n",
    "print(\"Linear, Brier pre (scaled df):\", round(brier_score_loss(y_test, p_lin_pre), 4))\n",
    "print(\"Linear, Brier post (isotonic):\", round(brier_score_loss(y_test, p_lin_post), 4))\n",
    "\n",
    "pt_pre, pp_pre   = calibration_curve(y_test, p_lin_pre,  n_bins=10, strategy=\"quantile\")\n",
    "pt_post, pp_post = calibration_curve(y_test, p_lin_post, n_bins=10, strategy=\"quantile\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(pp_pre, pt_pre, marker=\"o\", label=\"Linear, pre\")\n",
    "plt.plot(pp_post, pt_post, marker=\"o\", label=\"Linear, post (isotonic)\")\n",
    "plt.plot([0,1],[0,1],'--',lw=1,label=\"perfect\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"Observed\"); plt.title(\"Calibration, LinearSVC\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# RBF SVC\n",
    "# PRE: native probabilities from SVC(probability=True) use Platt scaling internally\n",
    "p_rbf_pre = probs_rbf\n",
    "\n",
    "# POST: external isotonic calibration on a validation slice\n",
    "val = train.iloc[-5000:]\n",
    "rbf_prefit = Pipeline([(\"pre\", pre), (\"svc\", SVC(C=1.0, kernel=\"rbf\", gamma=\"scale\", probability=True, random_state=42))])\n",
    "rbf_prefit.fit(X_train, y_train)\n",
    "rbf_cal = CalibratedClassifierCV(rbf_prefit, cv=\"prefit\", method=\"isotonic\")\n",
    "rbf_cal.fit(val[features], val[target])\n",
    "p_rbf_post = rbf_cal.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"RBF, Brier pre (Platt):\", round(brier_score_loss(y_test, p_rbf_pre), 4))\n",
    "print(\"RBF, Brier post (isotonic):\", round(brier_score_loss(y_test, p_rbf_post), 4))\n",
    "\n",
    "pt_pre, pp_pre   = calibration_curve(y_test, p_rbf_pre,  n_bins=10, strategy=\"quantile\")\n",
    "pt_post, pp_post = calibration_curve(y_test, p_rbf_post, n_bins=10, strategy=\"quantile\")\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(pp_pre, pt_pre, marker=\"o\", label=\"RBF, pre (Platt)\")\n",
    "plt.plot(pp_post, pt_post, marker=\"o\", label=\"RBF, post (isotonic)\")\n",
    "plt.plot([0,1],[0,1],'--',lw=1,label=\"perfect\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"Observed\"); plt.title(\"Calibration, RBF SVC\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14415ea6",
   "metadata": {},
   "source": [
    "#### Support-vector counts (linear & RBF) and threshold sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2cf3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support-vector counts & threshold sensitivity\n",
    "# True SV counts: need libsvm interface -> use SVC(kernel=\"linear\") for count (on a manageable sample if huge)\n",
    "# (LinearSVC doesn't expose support_; this is a standard workaround)\n",
    "sub_n = min(len(X_train), 20000)\n",
    "X_sub, y_sub = X_train.iloc[:sub_n], y_train.iloc[:sub_n]\n",
    "svc_linear = Pipeline([(\"pre\", pre), (\"svc\", SVC(kernel=\"linear\", C=1.0, probability=False, random_state=42))]).fit(X_sub, y_sub)\n",
    "n_sv_linear = int(svc_linear.named_steps[\"svc\"].n_support_.sum())\n",
    "\n",
    "svc_rbf = Pipeline([(\"pre\", pre), (\"svc\", SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", probability=True, random_state=42))]).fit(X_sub, y_sub)\n",
    "n_sv_rbf = int(svc_rbf.named_steps[\"svc\"].n_support_.sum())\n",
    "\n",
    "print(f\"Support vectors (linear SVC via libsvm): {n_sv_linear} / {len(X_sub)}\")\n",
    "print(f\"Support vectors (RBF SVC):              {n_sv_rbf} / {len(X_sub)}\")\n",
    "\n",
    "# Threshold sensitivity (Expected Value curve) using calibrated linear and RBF probs\n",
    "gain_tp, cost_fp, cost_fn, cost_tn = 100.0, 10.0, 40.0, 0.0\n",
    "def ev_curve(y_true, p):\n",
    "    ts = np.linspace(0.01, 0.99, 99); evs = []\n",
    "    for t in ts:\n",
    "        yhat = (p >= t).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, yhat).ravel()\n",
    "        evs.append(tp*gain_tp - fp*cost_fp - fn*cost_fn - tn*cost_tn)\n",
    "    return ts, np.array(evs)\n",
    "\n",
    "ts_lin, ev_lin = ev_curve(y_test, probs_lin)\n",
    "ts_rbf, ev_rbf = ev_curve(y_test, probs_rbf)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(ts_lin, ev_lin, label=\"Linear (calibrated)\")\n",
    "plt.plot(ts_rbf, ev_rbf, label=\"RBF\")\n",
    "plt.xlabel(\"Threshold\"); plt.ylabel(\"Expected value\"); plt.title(\"Threshold sensitivity\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39751b9f",
   "metadata": {},
   "source": [
    "#### Driver summary\n",
    "   - Linear: Top standardized coefficients (weights from LinearSVC after scaling/OHE)\n",
    "   - RBF: Permutation importances (+ PDPs) for top features\n",
    "   - PDPs are computed on the pipeline with raw column names; scikit-learn will route these through your ColumnTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b0e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver summary (Linear vs RBF)\n",
    "# Linear: top standardized coefficients\n",
    "lin_fit = lin  # already fitted pipeline\n",
    "feat_names = lin_fit.named_steps[\"pre\"].get_feature_names_out()\n",
    "coef = lin_fit.named_steps[\"svc\"].coef_.ravel()\n",
    "coef_df = pd.DataFrame({\"feature\": feat_names, \"coef\": coef}).sort_values(\"coef\", ascending=False)\n",
    "top_pos = coef_df.head(10)\n",
    "top_neg = coef_df.tail(10).sort_values(\"coef\")\n",
    "\n",
    "print(\"Top +coefficients (increase conversion odds):\")\n",
    "display(top_pos)\n",
    "print(\"Top -coefficients (decrease conversion odds):\")\n",
    "display(top_neg)\n",
    "\n",
    "# Plain-language driver summary. Linear: use top coefficients\n",
    "top_lin = coef_df.assign(absv=coef_df[\"coef\"].abs()).sort_values(\"absv\", ascending=False).head(4)\n",
    "share = float(top_lin[\"absv\"].sum() / coef_df[\"coef\"].abs().sum() + 1e-12)\n",
    "drivers = \", \".join(top_lin[\"feature\"].tolist())\n",
    "print(f\"Policy summary (Linear): ~{share*100:.0f}% of the decision signal comes from {drivers}. Prioritize data quality and controls here.\")\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.barh(top_pos[\"feature\"][::-1], top_pos[\"coef\"][::-1])\n",
    "plt.title(\"LinearSVC, Top positive standardized coefficients\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.barh(top_neg[\"feature\"], top_neg[\"coef\"])\n",
    "plt.title(\"LinearSVC, Top negative standardized coefficients\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# RBF: permutation importances + PDPs for top features (original column names)\n",
    "pi = permutation_importance(rbf, X_test, y_test, n_repeats=20, random_state=42, n_jobs=-1, scoring=\"average_precision\")\n",
    "fn_pi = list(features)\n",
    "pi_df = pd.DataFrame({\"feature\": fn_pi, \"mean\": pi.importances_mean, \"std\": pi.importances_std})\n",
    "pi_df = pi_df.sort_values(\"mean\", ascending=False)\n",
    "\n",
    "# Map transformed feature names back to original columns for PDP\n",
    "def to_original(feat):\n",
    "    if \"__\" in feat:\n",
    "        feat = feat.split(\"__\",1)[1]\n",
    "    for base in [\"ad_channel\",\"device\",\"region\",\"campaign\"]:\n",
    "        if feat.startswith(base + \"_\"):\n",
    "            return base\n",
    "    for base in [\"spend_l7\",\"pages_per_session\",\"sessions_l30\",\"time_on_site_s\",\"pricing_views_l7\",\"past_purchases\",\"discount_flag\",\"competitor_visits\"]:\n",
    "        if feat.startswith(base):\n",
    "            return base\n",
    "    return feat\n",
    "\n",
    "orig_rank = (pi_df.assign(orig=pi_df[\"feature\"].map(to_original))\n",
    "                 .groupby(\"orig\", as_index=False)[\"mean\"].sum()\n",
    "                 .sort_values(\"mean\", ascending=False))\n",
    "\n",
    "display(orig_rank.head(12))\n",
    "\n",
    "# Plain-language driver summary. RBF: use aggregated permutation importances\n",
    "top_rbf = orig_rank.head(4)\n",
    "share = float(top_rbf[\"mean\"].sum() / orig_rank[\"mean\"].sum() + 1e-12)\n",
    "drivers = \", \".join(top_rbf[\"orig\"].tolist())\n",
    "print(f\"Policy summary (RBF): ~{share*100:.0f}% of the decision signal comes from {drivers}. Prioritize data quality and controls here.\")\n",
    "\n",
    "# PDPs for top 3 original features\n",
    "top3 = orig_rank[\"orig\"].head(3).tolist()\n",
    "for f in top3:\n",
    "    try:\n",
    "        PartialDependenceDisplay.from_estimator(rbf, X_test, [f], kind=\"both\", grid_resolution=30, ice_lines_kw={\"alpha\":0.12})\n",
    "        plt.suptitle(f\"RBF SVC, PDP/ICE for {f}\")\n",
    "        plt.tight_layout(); plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"PDP failed for {f}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce68720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plain-language driver summary\n",
    "# For Linear: use top coefficients\n",
    "top_lin = coef_df.assign(absv=coef_df[\"coef\"].abs()).sort_values(\"absv\", ascending=False).head(4)\n",
    "share = float(top_lin[\"absv\"].sum() / coef_df[\"coef\"].abs().sum() + 1e-12)\n",
    "drivers = \", \".join(top_lin[\"feature\"].tolist())\n",
    "print(f\"Policy summary (Linear): ~{share*100:.0f}% of the decision signal comes from {drivers}. Prioritize data quality and controls here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e71873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF: use aggregated permutation importances\n",
    "top_rbf = orig_rank.head(4)\n",
    "share = float(top_rbf[\"mean\"].sum() / orig_rank[\"mean\"].sum() + 1e-12)\n",
    "drivers = \", \".join(top_rbf[\"orig\"].tolist())\n",
    "print(f\"Policy summary (RBF): ~{share*100:.0f}% of the decision signal comes from {drivers}. Prioritize data quality and controls here.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c341d9",
   "metadata": {},
   "source": [
    "#### Decision table (template): probability → action by season/segment with owners & SLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67ec4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision table mapping probabilities to actions by season/segment\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# Build helper columns: season from timestamp; segment examples\n",
    "test_ct = test.copy()\n",
    "test_ct[\"season\"] = test_ct[\"ts\"].dt.month%12//3 + 1  # 1=Winter,2=Spring,3=Summer,4=Fall\n",
    "test_ct[\"p_lin\"] = probs_lin\n",
    "test_ct[\"p_rbf\"] = probs_rbf\n",
    "\n",
    "# Choose one model's probabilities for actioning; here: calibrated linear\n",
    "test_ct[\"p\"] = test_ct[\"p_lin\"]\n",
    "\n",
    "# Define probability bands -> actions/owners/SLA\n",
    "def band(p):\n",
    "    if p >= 0.80: return \"P3: High-touch offer\"\n",
    "    if p >= 0.50: return \"P2: Standard offer\"\n",
    "    if p >= 0.30: return \"P1: Nurture\"\n",
    "    return \"P0: No action\"\n",
    "\n",
    "owner_map = {\n",
    "    \"P3: High-touch offer\": \"Sales (AE)\",\n",
    "    \"P2: Standard offer\": \"Lifecycle Marketing\",\n",
    "    \"P1: Nurture\": \"CRM / Email\",\n",
    "    \"P0: No action\": \"No owner\"\n",
    "}\n",
    "sla_map = {\n",
    "    \"P3: High-touch offer\": \"Respond < 24h\",\n",
    "    \"P2: Standard offer\": \"Campaign within 72h\",\n",
    "    \"P1: Nurture\": \"Weekly cadence\",\n",
    "    \"P0: No action\": \"—\"\n",
    "}\n",
    "\n",
    "test_ct[\"policy\"] = test_ct[\"p\"].apply(band)\n",
    "test_ct[\"owner\"]  = test_ct[\"policy\"].map(owner_map)\n",
    "test_ct[\"SLA\"]    = test_ct[\"policy\"].map(sla_map)\n",
    "\n",
    "# Summarize by season & a key segment (e.g., ad_channel); adjust to your needs\n",
    "summary = (test_ct.groupby([\"season\",\"ad_channel\",\"policy\"], as_index=False)\n",
    "                  .agg(n=(\"converted\",\"size\"),\n",
    "                       avg_p=(\"p\",\"mean\"),\n",
    "                       conv_rate=(target,\"mean\")))\n",
    "\n",
    "# Sort and display compact \"decision table\"\n",
    "summary = summary.sort_values([\"season\",\"ad_channel\",\"policy\",\"avg_p\"], ascending=[True, True, False, False])\n",
    "\n",
    "# Attach owners/SLA for each policy row\n",
    "summary[\"owner\"] = summary[\"policy\"].map(owner_map)\n",
    "summary[\"SLA\"]   = summary[\"policy\"].map(sla_map)\n",
    "display(summary.head(40))\n",
    "\n",
    "# Optional: export to CSV for ops handoff\n",
    "# summary.to_csv(\"svm_decision_table_by_season_segment.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
