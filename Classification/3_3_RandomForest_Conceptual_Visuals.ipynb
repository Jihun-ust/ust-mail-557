{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a563f1d7",
   "metadata": {},
   "source": [
    "\n",
    "# Random Forest — Conceptual Visualizations (Classification)\n",
    "\n",
    "**visual explanations** of how a Random Forest works:\n",
    "\n",
    "- A single decision tree produces **jagged** boundaries; a forest **smooths** them by voting.\n",
    "- **Bootstrapping (bagging)** gives each tree a different view of the data and enables **OOB** estimates.\n",
    "- More trees → **lower variance** up to diminishing returns.\n",
    "- We compare **Gini** vs **permutation** importances and show a **PDP** for intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa48d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt, warnings\n",
    "\n",
    "from sklearn.datasets import make_moons, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, average_precision_score)\n",
    "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
    "\n",
    "np.random.seed(12)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af130fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_decision_boundary(clf, X, y, title=\"Decision boundary\"):\n",
    "    x_min, x_max = X[:,0].min()-0.8, X[:,0].max()+0.8\n",
    "    y_min, y_max = X[:,1].min()-0.8, X[:,1].max()+0.8\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.25)\n",
    "    plt.scatter(X[:,0], X[:,1], c=y, s=12, alpha=0.75)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"x1\"); plt.ylabel(\"x2\")\n",
    "    plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55db6ee5",
   "metadata": {},
   "source": [
    "\n",
    "## Single Tree vs Forest (2D Moons)\n",
    "\n",
    "We use a 2D \"moons\" dataset to literally see the boundary: trees create **piecewise-constant** regions; forests **average** them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91cd3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = make_moons(n_samples=1200, noise=0.30, random_state=12)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=12)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=4, random_state=12)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300, max_depth=None, min_samples_leaf=3,\n",
    "                            oob_score=True, random_state=12, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Tree  — test accuracy:\", round(accuracy_score(y_test, tree.predict(X_test)), 3))\n",
    "print(\"Forest— test accuracy:\", round(accuracy_score(y_test, rf.predict(X_test)), 3))\n",
    "print(\"Forest— OOB score   :\", round(rf.oob_score_, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fc4e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_decision_boundary(tree, X_train, y_train, title=\"Single Decision Tree — Decision Boundary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_decision_boundary(rf, X_train, y_train, title=\"Random Forest — Decision Boundary (Smoothed by Voting)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dfbea5",
   "metadata": {},
   "source": [
    "\n",
    "## Bagging / Bootstrapping Intuition\n",
    "\n",
    "Each tree trains on a **bootstrap sample** of the data (sampled with replacement). Points not sampled for that tree are **OOB (out-of-bag)** for that tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbe9160",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train.shape[0]\n",
    "idx = np.arange(n)\n",
    "boot_idx = np.random.choice(idx, size=n, replace=True)\n",
    "oob_mask = np.ones(n, dtype=bool); oob_mask[boot_idx] = False\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(X_train[boot_idx,0], X_train[boot_idx,1], s=12, alpha=0.55, label=\"Bootstrap sample\")\n",
    "plt.scatter(X_train[oob_mask,0], X_train[oob_mask,1], s=12, alpha=0.95, label=\"OOB (this tree)\")\n",
    "plt.title(\"Bootstrapping: In-Bag vs Out-of-Bag Points\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5955683b",
   "metadata": {},
   "source": [
    "\n",
    "## Voting Intuition (Averaging Trees)\n",
    "\n",
    "The forest averages per-tree probabilities → **smoother** decisions than any single tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6624a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = X[:,0].min()-0.8, X[:,0].max()+0.8\n",
    "y_min, y_max = X[:,1].min()-0.8, X[:,1].max()+0.8\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 220),\n",
    "                     np.linspace(y_min, y_max, 220))\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "probs_grid = np.zeros(grid.shape[0])\n",
    "for est in rf.estimators_[:60]:  # sample 60 trees for speed\n",
    "    probs_grid += est.predict_proba(grid)[:,1]\n",
    "probs_grid /= 60.0\n",
    "Z = (probs_grid >= 0.5).astype(int).reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.contourf(xx, yy, Z, alpha=0.25)\n",
    "plt.scatter(X[:,0], X[:,1], c=y, s=12, alpha=0.75)\n",
    "plt.title(\"Forest Majority Vote (Averaged over Trees)\")\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d9ca9b",
   "metadata": {},
   "source": [
    "\n",
    "## OOB vs Validation Metrics\n",
    "\n",
    "OOB approximates test performance without a separate validation set (a *built-in* cross-validation from bootstrapping).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a591580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_test = rf.predict_proba(X_test)[:,1]\n",
    "print(\"Validation ROC-AUC:\", round(roc_auc_score(y_test, y_prob_test), 3))\n",
    "print(\"Validation PR-AUC :\", round(average_precision_score(y_test, y_prob_test), 3))\n",
    "print(\"OOB score (accuracy-like):\", round(rf.oob_score_, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56f8e56",
   "metadata": {},
   "source": [
    "\n",
    "## Effect of Number of Trees\n",
    "\n",
    "More trees reduce variance and stabilize metrics, up to diminishing returns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac859663",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [1, 5, 10, 30, 60, 100, 200, 400]\n",
    "accs = []; aucs = []\n",
    "for m in sizes:\n",
    "    mrf = RandomForestClassifier(n_estimators=m, min_samples_leaf=3, random_state=12, n_jobs=-1, oob_score=True)\n",
    "    mrf.fit(X_train, y_train)\n",
    "    p = mrf.predict_proba(X_test)[:,1]\n",
    "    accs.append(accuracy_score(y_test, mrf.predict(X_test)))\n",
    "    aucs.append(roc_auc_score(y_test, p))\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(sizes, accs, marker=\"o\")\n",
    "plt.xlabel(\"# Trees\"); plt.ylabel(\"Accuracy\"); plt.title(\"Accuracy vs Number of Trees\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(sizes, aucs, marker=\"o\")\n",
    "plt.xlabel(\"# Trees\"); plt.ylabel(\"ROC-AUC\"); plt.title(\"ROC-AUC vs Number of Trees\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f1db36",
   "metadata": {},
   "source": [
    "\n",
    "## What Drives Predictions? (Importances + PDP on Tabular Data)\n",
    "\n",
    "We switch to a 10‑feature tabular dataset to compare **Gini** vs **Permutation** importances, then plot a **PDP**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d57d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtab, ytab = make_classification(n_samples=2500, n_features=10, n_informative=4, n_redundant=2,\n",
    "                                 n_clusters_per_class=2, class_sep=1.1, random_state=12)\n",
    "Xtr, Xte, ytr, yte = train_test_split(Xtab, ytab, test_size=0.25, random_state=12, stratify=ytab)\n",
    "\n",
    "rf_tab = RandomForestClassifier(n_estimators=500, min_samples_leaf=2, random_state=12, n_jobs=-1, oob_score=True)\n",
    "rf_tab.fit(Xtr, ytr)\n",
    "\n",
    "gini_imp = rf_tab.feature_importances_\n",
    "order = np.argsort(gini_imp)[::-1]\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(range(len(order)), gini_imp[order])\n",
    "plt.xticks(range(len(order)), [f\"x{j}\" for j in order])\n",
    "plt.ylabel(\"Gini Importance\"); plt.title(\"Model-based (Gini) Importances\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "pi = permutation_importance(rf_tab, Xte, yte, n_repeats=20, random_state=12, n_jobs=-1, scoring=\"roc_auc\")\n",
    "pi_mean, pi_std = pi.importances_mean, pi.importances_std\n",
    "order2 = np.argsort(pi_mean)[::-1]\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(range(len(order2)), pi_mean[order2], yerr=1.96*pi_std[order2])\n",
    "plt.xticks(range(len(order2)), [f\"x{j}\" for j in order2])\n",
    "plt.ylabel(\"Permutation Importance (ΔAUC)\"); plt.title(\"Permutation Importances (95% CI)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "print(\"Tabular Validation ROC-AUC:\", round(roc_auc_score(yte, rf_tab.predict_proba(Xte)[:,1]), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c963b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feat = int(np.argmax(rf_tab.feature_importances_))\n",
    "PartialDependenceDisplay.from_estimator(rf_tab, Xte, [top_feat], kind=\"average\", grid_resolution=30)\n",
    "plt.suptitle(f\"Partial Dependence — feature x{top_feat}\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d40902",
   "metadata": {},
   "source": [
    "\n",
    "### Key Takeaways\n",
    "- A Random Forest **reduces variance** vs a single tree by averaging many de-correlated trees.\n",
    "- **OOB** estimates come for free from bootstrapping and usually track validation metrics.\n",
    "- **Permutation importances** tell you which features most change real predictions; **PDP** shows average effect shape.\n",
    "- Adding more trees helps until the curve flattens; then you’re at diminishing returns.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
