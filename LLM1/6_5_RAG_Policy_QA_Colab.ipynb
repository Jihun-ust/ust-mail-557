{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10630c58",
   "metadata": {},
   "source": [
    "\n",
    "# RAG Chatbot (Colab, Private) — PDF → Preprocess → Index → Ask\n",
    "**Purpose:** Quickly experience a Retrieval‑Augmented Generation (RAG) flow entirely inside a Colab/Jupyter notebook.  \n",
    "**Stack:** `ipywidgets` UI, `pypdf` for extraction, `scikit-learn` for vector search, Google **Gemini** API for embeddings & generation.\n",
    "\n",
    "> This notebook looks for the environment variable `GOOGLE_API_KEY`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f2fdf4",
   "metadata": {},
   "source": [
    "## Imports & Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb899ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install pypdf ipywidgets reportlab\n",
    "\n",
    "import os, io, requests, textwrap, tempfile\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "from pypdf import PdfReader\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb750a36",
   "metadata": {},
   "source": [
    "## Gemini API Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b1e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
    "    _GEMINI_READY = bool(userdata.get('GOOGLE_API_KEY'))\n",
    "except Exception:\n",
    "    print(\"Install google-generativeai to enable live calls.\")\n",
    "    _GEMINI_READY = False\n",
    "\n",
    "GENERATION_MODEL = \"gemini-2.5-flash\"\n",
    "EMBED_MODEL      = \"gemini-embedding-001\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50da98e",
   "metadata": {},
   "source": [
    "## Default PDF Download & Sample Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b06db",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_POLICY_PDF_URLS = [\n",
    "    # FERPA(Family Educational Rights and Privacy Act) documents for dafault samples\n",
    "    \"https://studentprivacy.ed.gov/sites/default/files/resource_document/file/An%20Eligible%20Student%20Guide%20to%20FERPA_0.pdf\",\n",
    "    \"https://studentprivacy.ed.gov/sites/default/files/resource_document/file/A%20parent%20guide%20to%20ferpa_508.pdf\"\n",
    "]\n",
    "\n",
    "def download_pdf(url: str) -> bytes:\n",
    "    resp = requests.get(url, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    # Some servers may not set proper PDF headers; we still try bytes\n",
    "    return resp.content\n",
    "\n",
    "def create_local_sample_policy_pdf(path: Path):\n",
    "    # Fallback: generate a tiny FERPA-related PDF so the pipeline always works offline.\n",
    "    sample_text = textwrap.dedent('''\n",
    "        Sample FERPA Policy (Demo)\n",
    "        --------------------------\n",
    "        1. Rights of Parents and Eligible Students:\n",
    "           Parents or eligible students have the right to inspect and review education records\n",
    "           maintained by the school.\n",
    "        2. Amendment of Records:\n",
    "           Parents or eligible students may request corrections to records they believe are inaccurate\n",
    "           or misleading.\n",
    "        3. Consent for Disclosure:\n",
    "           Schools generally must have written permission before releasing information from a student's\n",
    "           education record.\n",
    "        4. Exceptions:\n",
    "           FERPA allows disclosure without consent to certain parties such as school officials with\n",
    "           legitimate educational interests, or in cases of health and safety emergencies.\n",
    "        5. Directory Information:\n",
    "           Schools may disclose \"directory\" information (such as name, address, phone number, dates of\n",
    "           attendance) without consent, but must inform parents and eligible students and allow them\n",
    "           time to opt out.\n",
    "        6. Compliance Note:\n",
    "           This demo text is adapted for instructional purposes only and is not a full legal document.\n",
    "    ''').strip()\n",
    "\n",
    "    c = canvas.Canvas(str(path), pagesize=letter)\n",
    "    width, height = letter\n",
    "    y = height - 72\n",
    "    for line in sample_text.splitlines():\n",
    "        c.drawString(72, y, line)\n",
    "        y -= 18\n",
    "        if y < 72:\n",
    "            c.showPage()\n",
    "            y = height - 72\n",
    "    c.save()\n",
    "\n",
    "def ensure_pdf_bytes(uploaded: bytes = None, fallback_url: str = None):\n",
    "    \"\"\"Returns (pdf_bytes, source_label). Tries uploaded, then fallback_url, then local sample.\"\"\"\n",
    "    if uploaded:\n",
    "        return uploaded, \"uploaded_file.pdf\"\n",
    "    urls = [fallback_url] if fallback_url else [] \n",
    "    urls += DEFAULT_POLICY_PDF_URLS\n",
    "    for u in urls:\n",
    "        try:\n",
    "            b = download_pdf(u)\n",
    "            return b, u\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not fetch {u}: {e}\")\n",
    "    # Last resort: generate a local PDF with sample text\n",
    "    tmp = Path(tempfile.gettempdir()) / \"sample_policy.pdf\"\n",
    "    create_local_sample_policy_pdf(tmp)\n",
    "    with open(tmp, \"rb\") as f:\n",
    "        return f.read(), \"local_sample_policy.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd7b48",
   "metadata": {},
   "source": [
    "## PDF to Pages & Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b6ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PageText:\n",
    "    page_num: int\n",
    "    text: str\n",
    "\n",
    "def pdf_to_pages(pdf_bytes: bytes):\n",
    "    reader = PdfReader(io.BytesIO(pdf_bytes))\n",
    "    pages = []\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        try:\n",
    "            txt = page.extract_text() or \"\"\n",
    "        except Exception:\n",
    "            txt = \"\"\n",
    "        txt = \" \".join(txt.split())\n",
    "        pages.append(PageText(page_num=i+1, text=txt))\n",
    "    return pages\n",
    "\n",
    "def chunk_text(text: str, chunk_chars: int = 1200, overlap: int = 200):\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    n = len(text)\n",
    "    while i < n:\n",
    "        end = min(i + chunk_chars, n)\n",
    "        chunk = text[i:end]\n",
    "        chunks.append(chunk)\n",
    "        if end == n:\n",
    "            break\n",
    "        i = end - overlap if end - overlap > i else end\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b664390b",
   "metadata": {},
   "source": [
    "## Embedding & Vector Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_texts(texts, model=EMBED_MODEL):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    rows = []\n",
    "    for t in texts:\n",
    "        resp = genai.embed_content(model=model, content=t)\n",
    "        emb = resp.get(\"embedding\", resp)\n",
    "        if isinstance(emb, dict) and \"values\" in emb:\n",
    "            v = emb[\"values\"]\n",
    "        else:\n",
    "            v = emb\n",
    "        rows.append(np.asarray(v, dtype=float))\n",
    "    X = np.vstack(rows)\n",
    "    if X.ndim != 2:\n",
    "        raise RuntimeError(f\"Expected 2D embeddings, got {X.shape}\")\n",
    "    return X\n",
    "\n",
    "class SimpleVectorIndex:\n",
    "    def __init__(self, embeddings, meta):\n",
    "        self.embeddings = np.asarray(embeddings, dtype=float)\n",
    "        if self.embeddings.ndim != 2:\n",
    "            raise ValueError(f\"embeddings must be 2D, got {self.embeddings.shape}\")\n",
    "        self.meta = meta\n",
    "        self.n = self.embeddings.shape[0]\n",
    "\n",
    "        n_neighbors = max(1, min(10, self.n))\n",
    "        self.nn = NearestNeighbors(n_neighbors=n_neighbors, metric=\"cosine\")\n",
    "        self.nn.fit(self.embeddings)\n",
    "\n",
    "    def search(self, query_vec, top_k=5):\n",
    "        q = np.asarray(query_vec, dtype=float).reshape(1, -1)\n",
    "        k = max(1, min(int(top_k), self.n))\n",
    "\n",
    "        # Fast-path for single-item indexes\n",
    "        if self.n == 1:\n",
    "            return [(0, 1.0)]\n",
    "\n",
    "        distances, indices = self.nn.kneighbors(q, n_neighbors=k)\n",
    "        results = []\n",
    "        for d, idx in zip(distances[0], indices[0]):\n",
    "            sim = 1.0 - float(d)  # cosine distance -> similarity\n",
    "            results.append((int(idx), sim))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1f4b90",
   "metadata": {},
   "source": [
    "## RAG Prompt & Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1008c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_SYSTEM_PROMPT = '''You are a careful assistant. Answer ONLY using the provided context from the approved document(s).\n",
    "If the answer is not present in the context, say \"I don't know based on the approved documents.\"\n",
    "Always cite page numbers like (p. X) when relevant.\n",
    "Keep answers concise, accurate, and policy-aligned.'''\n",
    "\n",
    "def build_context(snippets, max_tokens: int = 1500):\n",
    "    buf = []\n",
    "    used = 0\n",
    "    for s in snippets:\n",
    "        header = f\"[Source: {s['source']} p.{s['page']}]\"\n",
    "        body = s[\"text\"]\n",
    "        piece = header + \"\\n\" + body + \"\\n\"\n",
    "        if used + len(piece) > max_tokens * 4:\n",
    "            break\n",
    "        buf.append(piece)\n",
    "        used += len(piece)\n",
    "    return \"\\n\".join(buf)\n",
    "\n",
    "def answer_with_gemini(question: str, context: str):\n",
    "    prompt = f\"{RAG_SYSTEM_PROMPT}\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "    resp = genai.GenerativeModel(GENERATION_MODEL).generate_content(prompt)\n",
    "    return resp.text or \"(no response)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c22931a",
   "metadata": {},
   "source": [
    "\n",
    "## Demo workflow\n",
    "1. **Load a PDF** by uploading or pasting a URL (or rely on a default FERPA PDF).  \n",
    "2. Click **Preprocess & Chunk** and then **Build Index**.  \n",
    "3. Ask: *What is FERPA?”* (or any relevant question).  \n",
    "\n",
    "> Tweak chunk size, overlap, and Top‑K to see how retrieval quality changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d8f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widgets\n",
    "upload = widgets.FileUpload(accept=\".pdf\", multiple=False)\n",
    "url_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"Optional: paste a PDF URL (used if no file uploaded)\",\n",
    "    description=\"PDF URL:\"\n",
    ")\n",
    "chunk_slider = widgets.IntSlider(value=500, min=200, max=1000, step=100, description=\"Chunk size\")\n",
    "overlap_slider = widgets.IntSlider(value=100, min=0, max=400, step=50, description=\"Overlap\")\n",
    "topk_slider = widgets.IntSlider(value=5, min=1, max=10, step=1, description=\"Top-K\")\n",
    "load_btn = widgets.Button(description=\"Load PDF\", button_style=\"primary\")\n",
    "prep_btn = widgets.Button(description=\"Preprocess & Chunk\", button_style=\"warning\")\n",
    "index_btn = widgets.Button(description=\"Build\", button_style=\"info\")\n",
    "\n",
    "status_out = widgets.Output(layout={'border': '1px solid #ddd'})\n",
    "prep_out = widgets.Output(layout={'border': '1px solid #ddd'})\n",
    "search_out = widgets.Output(layout={'border': '1px solid #ddd'})\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>1) Load a PDF</h3>\"),\n",
    "    widgets.HTML(\"Upload a PDF file or provide a URL to a publicly accessible PDF. If both are provided, the uploaded file is used.\"),\n",
    "    widgets.HTML(\"Tip: If no PDF is provided, a sample FERPA policy will be used.\"),\n",
    "    widgets.HBox([upload]),\n",
    "    url_input,\n",
    "    load_btn,\n",
    "    status_out,\n",
    "    widgets.HTML(\"<h3>2) Preprocess PDF</h3>\"),\n",
    "    chunk_slider, overlap_slider, prep_btn, prep_out,\n",
    "    widgets.HTML(\"<h3>3) Build Index</h3>\"),\n",
    "    topk_slider, index_btn, search_out,\n",
    "]))\n",
    "\n",
    "STATE = {\"source_label\": None, \"pages\": [], \"chunks\": [], \"chunk_meta\": [], \"emb\": None, \"index\": None}\n",
    "\n",
    "def on_load_clicked(_):\n",
    "    status_out.clear_output()\n",
    "    with status_out:\n",
    "        try:\n",
    "            uploaded_bytes = None\n",
    "            if upload.value:\n",
    "                first = list(upload.value.values())[0]\n",
    "                uploaded_bytes = first[\"content\"]\n",
    "            url = url_input.value.strip() or None\n",
    "            pdf_bytes, src = ensure_pdf_bytes(uploaded=uploaded_bytes, fallback_url=url)\n",
    "            pages = pdf_to_pages(pdf_bytes)\n",
    "            STATE[\"source_label\"] = src\n",
    "            STATE[\"pages\"] = pages\n",
    "            print(f\"Loaded PDF from: {src}\")\n",
    "            print(f\"   Pages extracted: {len(pages)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Load failed: {e}\")\n",
    "\n",
    "def on_prep_clicked(_):\n",
    "    prep_out.clear_output()\n",
    "    with prep_out:\n",
    "        if not STATE[\"pages\"]:\n",
    "            print(\"No PDF loaded yet.\")\n",
    "            return\n",
    "        chunk_chars = int(chunk_slider.value)\n",
    "        overlap = int(overlap_slider.value)\n",
    "        chunks, meta = [], []\n",
    "        src = STATE[\"source_label\"]\n",
    "        for p in STATE[\"pages\"]:\n",
    "            if not p.text:\n",
    "                continue\n",
    "            cks = chunk_text(p.text, chunk_chars=chunk_chars, overlap=overlap)\n",
    "            for c in cks:\n",
    "                chunks.append(c)\n",
    "                meta.append({\"source\": src, \"page\": p.page_num, \"text\": c})\n",
    "        STATE[\"chunks\"] = chunks\n",
    "        STATE[\"chunk_meta\"] = meta\n",
    "        print(f\"Created {len(chunks)} chunks across {len(STATE['pages'])} pages.\")\n",
    "\n",
    "def on_index_clicked(_):\n",
    "    search_out.clear_output()\n",
    "    with search_out:\n",
    "        if not STATE[\"chunks\"]:\n",
    "            print(\"No chunks to index. Run preprocessing first.\")\n",
    "            return\n",
    "        try:\n",
    "            print(\"Embedding chunks... (this may take a moment)\")\n",
    "            emb = embed_texts(STATE[\"chunks\"])\n",
    "            idx = SimpleVectorIndex(emb, STATE[\"chunk_meta\"])\n",
    "            STATE[\"emb\"] = emb\n",
    "            STATE[\"index\"] = idx\n",
    "            print(f\"Index built with shape {emb.shape}.\")\n",
    "            print(\"Ready to answer questions. Next cell will display the chat interface.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Index build failed: {e}\")\n",
    "\n",
    "def on_ask(q_input):\n",
    "    if not STATE[\"index\"]:\n",
    "        return \"Error - Build the index first.\"\n",
    "    if not q_input:\n",
    "        return \"Enter a question.\"\n",
    "    q = q_input\n",
    "    answer_out = ''\n",
    "\n",
    "    try:\n",
    "        qvec = embed_texts([q])[0]\n",
    "        results = STATE[\"index\"].search(qvec, top_k=int(topk_slider.value))\n",
    "        snippets = []\n",
    "        for idx, sim in results:\n",
    "            m = STATE[\"chunk_meta\"][idx]\n",
    "            snippets.append({\"source\": m[\"source\"], \"page\": m[\"page\"], \"text\": m[\"text\"], \"score\": sim})\n",
    "        context = build_context(snippets)\n",
    "        # print(\"Top matches:\")\n",
    "        # for s in snippets[:3]:\n",
    "        #     print(f\"  - p.{s['page']} (sim≈{s['score']:.3f})\")\n",
    "        # print(\"\\nAnswer:\\n\")\n",
    "        ans = answer_with_gemini(q, context)\n",
    "        answer_out += f\"{ans}\\n\"\n",
    "        answer_out += f\"\\nContext used (truncated):\\n{context[:1000]}...\\n\"\n",
    "        return answer_out\n",
    "    except Exception as e:\n",
    "        return f\"Q&A failed: {e}\"\n",
    "\n",
    "load_btn.on_click(on_load_clicked)\n",
    "prep_btn.on_click(on_prep_clicked)\n",
    "index_btn.on_click(on_index_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c52a7e0",
   "metadata": {},
   "source": [
    "## Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ddc8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_box = widgets.Output()\n",
    "input_box = widgets.Text(placeholder=\"Type a message and press Enter…\")\n",
    "send_btn = widgets.Button(description=\"Send\")\n",
    "\n",
    "history = []\n",
    "\n",
    "def render_chat():\n",
    "    chat_box.clear_output()\n",
    "    with chat_box:\n",
    "        for u, a in history:\n",
    "            display(Markdown(f\"**You:** {u}\"))\n",
    "            display(Markdown(f\"**Bot:** {a}\"))\n",
    "\n",
    "def send_message(_=None):\n",
    "    user_msg = input_box.value.strip()\n",
    "    if not user_msg:\n",
    "        return\n",
    "    input_box.value = \"\"\n",
    "\n",
    "    # Generate a reply\n",
    "    context = \"\\n\".join([f\"User: {u}\\nAssistant: {a}\" for u, a in history])\n",
    "    prompt = (context + f\"\\nUser: {user_msg}\\nAssistant:\").strip()\n",
    "\n",
    "    try:\n",
    "        resp = on_ask(prompt)\n",
    "        bot_msg = resp or \"(no response)\"\n",
    "    except Exception as e:\n",
    "        bot_msg = f\"(error) {e}\"\n",
    "\n",
    "    history.append((user_msg, bot_msg))\n",
    "    render_chat()\n",
    "\n",
    "send_btn.on_click(send_message)\n",
    "input_box.on_submit(send_message)\n",
    "\n",
    "display(widgets.VBox([chat_box, widgets.HBox([input_box, send_btn])]))\n",
    "render_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
