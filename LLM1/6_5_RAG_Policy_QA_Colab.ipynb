{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10630c58",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ§ª RAG Chatbot (Colab, Private) â€” PDF â†’ Preprocess â†’ Index â†’ Ask\n",
    "**Purpose:** Quickly experience a Retrievalâ€‘Augmented Generation (RAG) flow entirely inside a Colab/Jupyter notebook without exposing a public URL.  \n",
    "**Stack:** `ipywidgets` UI, `pypdf` for extraction, `scikit-learn` for vector search, Google **Gemini** API for embeddings & generation.\n",
    "\n",
    "> **Tip:** In Colab, set your key with: `import os; os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_KEY_HERE\"`  \n",
    "> This notebook looks for the environment variable `GOOGLE_API_KEY`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb899ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install google-generativeai pypdf scikit-learn ipywidgets reportlab\n",
    "\n",
    "import os, io, json, math, time, requests, textwrap, tempfile\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "import google.generativeai as genai\n",
    "from pypdf import PdfReader\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b1e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
    "    _GEMINI_READY = bool(userdata.get('GOOGLE_API_KEY'))\n",
    "except Exception:\n",
    "    print(\"Install google-generativeai to enable live calls.\")\n",
    "    _GEMINI_READY = False\n",
    "\n",
    "GENERATION_MODEL = \"gemini-2.5-flash-lite\"   # You can change to another available model\n",
    "EMBED_MODEL      = \"text-embedding-004\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b06db",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_POLICY_PDF_URLS = [\n",
    "    # FERPA(Family Educational Rights and Privacy Act) documents for dafault samples\n",
    "    \"https://studentprivacy.ed.gov/sites/default/files/resource_document/file/An%20Eligible%20Student%20Guide%20to%20FERPA_0.pdf\",\n",
    "    \"https://studentprivacy.ed.gov/sites/default/files/resource_document/file/A%20parent%20guide%20to%20ferpa_508.pdf\"\n",
    "]\n",
    "\n",
    "def download_pdf(url: str) -> bytes:\n",
    "    resp = requests.get(url, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    # Some servers may not set proper PDF headers; we still try bytes\n",
    "    return resp.content\n",
    "\n",
    "def create_local_sample_policy_pdf(path: Path):\n",
    "    # Fallback: generate a tiny FERPA-related PDF so the pipeline always works offline.\n",
    "    sample_text = textwrap.dedent('''\n",
    "        Sample FERPA Policy (Demo)\n",
    "        --------------------------\n",
    "        1. Rights of Parents and Eligible Students:\n",
    "           Parents or eligible students have the right to inspect and review education records\n",
    "           maintained by the school.\n",
    "        2. Amendment of Records:\n",
    "           Parents or eligible students may request corrections to records they believe are inaccurate\n",
    "           or misleading.\n",
    "        3. Consent for Disclosure:\n",
    "           Schools generally must have written permission before releasing information from a student's\n",
    "           education record.\n",
    "        4. Exceptions:\n",
    "           FERPA allows disclosure without consent to certain parties such as school officials with\n",
    "           legitimate educational interests, or in cases of health and safety emergencies.\n",
    "        5. Directory Information:\n",
    "           Schools may disclose \"directory\" information (such as name, address, phone number, dates of\n",
    "           attendance) without consent, but must inform parents and eligible students and allow them\n",
    "           time to opt out.\n",
    "        6. Compliance Note:\n",
    "           This demo text is adapted for instructional purposes only and is not a full legal document.\n",
    "    ''').strip()\n",
    "\n",
    "    c = canvas.Canvas(str(path), pagesize=letter)\n",
    "    width, height = letter\n",
    "    y = height - 72\n",
    "    for line in sample_text.splitlines():\n",
    "        c.drawString(72, y, line)\n",
    "        y -= 18\n",
    "        if y < 72:\n",
    "            c.showPage()\n",
    "            y = height - 72\n",
    "    c.save()\n",
    "\n",
    "def ensure_pdf_bytes(uploaded: bytes = None, fallback_url: str = None):\n",
    "    \"\"\"Returns (pdf_bytes, source_label). Tries uploaded, then fallback_url, then local sample.\"\"\"\n",
    "    if uploaded:\n",
    "        return uploaded, \"uploaded_file.pdf\"\n",
    "    urls = [fallback_url] if fallback_url else [] \n",
    "    urls += DEFAULT_POLICY_PDF_URLS\n",
    "    for u in urls:\n",
    "        try:\n",
    "            b = download_pdf(u)\n",
    "            return b, u\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Could not fetch {u}: {e}\")\n",
    "    # Last resort: generate a local PDF with sample text\n",
    "    tmp = Path(tempfile.gettempdir()) / \"sample_policy.pdf\"\n",
    "    create_local_sample_policy_pdf(tmp)\n",
    "    with open(tmp, \"rb\") as f:\n",
    "        return f.read(), \"local_sample_policy.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b6ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class PageText:\n",
    "    page_num: int\n",
    "    text: str\n",
    "\n",
    "def pdf_to_pages(pdf_bytes: bytes):\n",
    "    reader = PdfReader(io.BytesIO(pdf_bytes))\n",
    "    pages = []\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        try:\n",
    "            txt = page.extract_text() or \"\"\n",
    "        except Exception:\n",
    "            txt = \"\"\n",
    "        txt = \" \".join(txt.split())\n",
    "        pages.append(PageText(page_num=i+1, text=txt))\n",
    "    return pages\n",
    "\n",
    "def chunk_text(text: str, chunk_chars: int = 1200, overlap: int = 200):\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    n = len(text)\n",
    "    while i < n:\n",
    "        end = min(i + chunk_chars, n)\n",
    "        chunk = text[i:end]\n",
    "        chunks.append(chunk)\n",
    "        if end == n:\n",
    "            break\n",
    "        i = end - overlap if end - overlap > i else end\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_texts(texts):\n",
    "    embeddings = []\n",
    "    B = 64\n",
    "    for i in range(0, len(texts), B):\n",
    "        batch = texts[i:i+B]\n",
    "        resp = genai.embed_content(model=\"text-embedding-004\", content=batch)\n",
    "        vecs = [r[\"embedding\"] for r in resp[\"embedding\"]]\n",
    "        embeddings.extend(vecs)\n",
    "    return np.array(embeddings, dtype=np.float32)\n",
    "\n",
    "class SimpleVectorIndex:\n",
    "    def __init__(self, embeddings, meta):\n",
    "        self.embeddings = embeddings\n",
    "        self.meta = meta\n",
    "        self.nn = NearestNeighbors(n_neighbors=10, metric=\"cosine\")\n",
    "        self.nn.fit(self.embeddings)\n",
    "    def search(self, query_vec, top_k=5):\n",
    "        distances, indices = self.nn.kneighbors(query_vec.reshape(1, -1), n_neighbors=top_k)\n",
    "        results = []\n",
    "        for d, idx in zip(distances[0], indices[0]):\n",
    "            results.append((int(idx), float(1.0 - d)))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1008c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_SYSTEM_PROMPT = '''You are a careful assistant. Answer ONLY using the provided context from the approved document(s).\n",
    "If the answer is not present in the context, say \"I don't know based on the approved documents.\"\n",
    "Always cite page numbers like (p. X) when relevant.\n",
    "Keep answers concise, accurate, and policy-aligned.'''\n",
    "\n",
    "def build_context(snippets, max_tokens: int = 1500):\n",
    "    buf = []\n",
    "    used = 0\n",
    "    for s in snippets:\n",
    "        header = f\"[Source: {s['source']} p.{s['page']}]\"\n",
    "        body = s[\"text\"]\n",
    "        piece = header + \"\\n\" + body + \"\\n\"\n",
    "        if used + len(piece) > max_tokens * 4:\n",
    "            break\n",
    "        buf.append(piece)\n",
    "        used += len(piece)\n",
    "    return \"\\n\".join(buf)\n",
    "\n",
    "def answer_with_gemini(question: str, context: str):\n",
    "    prompt = f\"{RAG_SYSTEM_PROMPT}\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "    resp = genai.GenerativeModel(\"gemini-2.5-flash-lite\").generate_content(prompt)\n",
    "    return resp.text or \"(no response)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d8f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Widgets ---\n",
    "upload = widgets.FileUpload(accept=\".pdf\", multiple=False)\n",
    "url_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"Optional: paste a PDF URL (used if no file uploaded)\",\n",
    "    description=\"PDF URL:\"\n",
    ")\n",
    "chunk_slider = widgets.IntSlider(value=1200, min=400, max=3000, step=100, description=\"Chunk size\")\n",
    "overlap_slider = widgets.IntSlider(value=200, min=0, max=800, step=50, description=\"Overlap\")\n",
    "topk_slider = widgets.IntSlider(value=5, min=1, max=10, step=1, description=\"Top-K\")\n",
    "load_btn = widgets.Button(description=\"1) Load PDF\", button_style=\"primary\")\n",
    "prep_btn = widgets.Button(description=\"2) Preprocess & Chunk\", button_style=\"warning\")\n",
    "index_btn = widgets.Button(description=\"3) Build Index\", button_style=\"info\")\n",
    "q_input = widgets.Text(placeholder=\"Ask a questionâ€¦ (e.g., 'How many weeks of parental leave?')\", description=\"Question:\")\n",
    "ask_btn = widgets.Button(description=\"4) Ask\", button_style=\"success\")\n",
    "\n",
    "status_out = widgets.Output()\n",
    "prep_out = widgets.Output(layout={'border': '1px solid #ddd'})\n",
    "search_out = widgets.Output(layout={'border': '1px solid #ddd'})\n",
    "answer_out = widgets.Output(layout={'border': '1px solid #ddd'})\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>ðŸ“„ Load a PDF</h3>\"),\n",
    "    widgets.HBox([upload]),\n",
    "    url_input,\n",
    "    load_btn,\n",
    "    status_out,\n",
    "    widgets.HTML(\"<h3>ðŸ§° Preprocess</h3>\"),\n",
    "    chunk_slider, overlap_slider, prep_btn, prep_out,\n",
    "    widgets.HTML(\"<h3>ðŸ”Ž Index</h3>\"),\n",
    "    topk_slider, index_btn, search_out,\n",
    "    widgets.HTML(\"<h3>ðŸ’¬ Ask</h3>\"),\n",
    "    q_input, ask_btn, answer_out\n",
    "]))\n",
    "\n",
    "STATE = {\"source_label\": None, \"pages\": [], \"chunks\": [], \"chunk_meta\": [], \"emb\": None, \"index\": None}\n",
    "\n",
    "def on_load_clicked(_):\n",
    "    status_out.clear_output()\n",
    "    with status_out:\n",
    "        try:\n",
    "            uploaded_bytes = None\n",
    "            if upload.value:\n",
    "                first = list(upload.value.values())[0]\n",
    "                uploaded_bytes = first[\"content\"]\n",
    "            url = url_input.value.strip() or None\n",
    "            pdf_bytes, src = ensure_pdf_bytes(uploaded=uploaded_bytes, fallback_url=url)\n",
    "            pages = pdf_to_pages(pdf_bytes)\n",
    "            STATE[\"source_label\"] = src\n",
    "            STATE[\"pages\"] = pages\n",
    "            print(f\"âœ… Loaded PDF from: {src}\")\n",
    "            print(f\"   Pages extracted: {len(pages)}\")\n",
    "            if len(pages) and pages[0].text[:200].strip():\n",
    "                print(f\"   First 200 chars: {pages[0].text[:200]}...\")\n",
    "            else:\n",
    "                print(\"   (Warning) First page seems to have little or no extractable text.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Load failed: {e}\")\n",
    "\n",
    "def on_prep_clicked(_):\n",
    "    prep_out.clear_output()\n",
    "    with prep_out:\n",
    "        if not STATE[\"pages\"]:\n",
    "            print(\"âš ï¸ No PDF loaded yet.\")\n",
    "            return\n",
    "        chunk_chars = int(chunk_slider.value)\n",
    "        overlap = int(overlap_slider.value)\n",
    "        chunks, meta = [], []\n",
    "        src = STATE[\"source_label\"]\n",
    "        for p in STATE[\"pages\"]:\n",
    "            if not p.text:\n",
    "                continue\n",
    "            cks = chunk_text(p.text, chunk_chars=chunk_chars, overlap=overlap)\n",
    "            for c in cks:\n",
    "                chunks.append(c)\n",
    "                meta.append({\"source\": src, \"page\": p.page_num, \"text\": c})\n",
    "        STATE[\"chunks\"] = chunks\n",
    "        STATE[\"chunk_meta\"] = meta\n",
    "        print(f\"âœ… Created {len(chunks)} chunks across {len(STATE['pages'])} pages.\")\n",
    "        for i in range(min(3, len(chunks))):\n",
    "            print(f\"\\n--- Chunk {i+1} (p.{meta[i]['page']}) ---\\n{chunks[i][:400]}...\")\n",
    "\n",
    "def on_index_clicked(_):\n",
    "    search_out.clear_output()\n",
    "    with search_out:\n",
    "        if not STATE[\"chunks\"]:\n",
    "            print(\"âš ï¸ No chunks to index. Run preprocessing first.\")\n",
    "            return\n",
    "        try:\n",
    "            print(\"ðŸ”„ Embedding chunks... (this may take a moment)\")\n",
    "            emb = embed_texts(STATE[\"chunks\"])\n",
    "            idx = SimpleVectorIndex(emb, STATE[\"chunk_meta\"])\n",
    "            STATE[\"emb\"] = emb\n",
    "            STATE[\"index\"] = idx\n",
    "            print(f\"âœ… Index built with shape {emb.shape}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Index build failed: {e}\")\n",
    "\n",
    "def on_ask_clicked(_):\n",
    "    answer_out.clear_output()\n",
    "    with answer_out:\n",
    "        if not STATE[\"index\"]:\n",
    "            print(\"âš ï¸ Build the index first.\")\n",
    "            return\n",
    "        if not q_input.value.strip():\n",
    "            print(\"âš ï¸ Enter a question.\")\n",
    "            return\n",
    "        q = q_input.value.strip()\n",
    "        try:\n",
    "            qvec = embed_texts([q])[0]\n",
    "            results = STATE[\"index\"].search(qvec, top_k=int(topk_slider.value))\n",
    "            snippets = []\n",
    "            for idx, sim in results:\n",
    "                m = STATE[\"chunk_meta\"][idx]\n",
    "                snippets.append({\"source\": m[\"source\"], \"page\": m[\"page\"], \"text\": m[\"text\"], \"score\": sim})\n",
    "            context = build_context(snippets)\n",
    "            print(\"ðŸ”Ž Top matches:\")\n",
    "            for s in snippets[:3]:\n",
    "                print(f\"  - p.{s['page']} (simâ‰ˆ{s['score']:.3f})\")\n",
    "            print(\"\\nðŸ¤– Answer:\")\n",
    "            ans = answer_with_gemini(q, context)\n",
    "            display(Markdown(ans))\n",
    "            print(\"\\nðŸ“š Context used (truncated):\\n\", context[:1000], \"...\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Q&A failed: {e}\")\n",
    "\n",
    "load_btn.on_click(on_load_clicked)\n",
    "prep_btn.on_click(on_prep_clicked)\n",
    "index_btn.on_click(on_index_clicked)\n",
    "ask_btn.on_click(on_ask_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c22931a",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ”¬ Quick-Start\n",
    "1. **Load a PDF** by uploading or pasting a URL (or rely on a default public Creative Commons license PDF).  \n",
    "2. Click **Preprocess & Chunk** and then **Build Index**.  \n",
    "3. Ask: *â€œHow many weeks of parental leave?â€* (or any relevant policy question).  \n",
    "\n",
    "> Tweak chunk size, overlap, and Topâ€‘K to see how retrieval quality changes.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
